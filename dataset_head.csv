code,language,model,split,target,source,features,cleaned_code
"def order_phase_diagram(lines, stable_entries, unstable_entries, ordering):
    """"""
    Orders the entries (their coordinates) in a phase diagram plot according
    to the user specified ordering.
    Ordering should be given as ['Up', 'Left', 'Right'], where Up,
    Left and Right are the names of the entries in the upper, left and right
    corners of the triangle respectively.

    Args:
        lines: list of list of coordinates for lines in the PD.
        stable_entries: {coordinate : entry} for each stable node in the
            phase diagram. (Each coordinate can only have one stable phase)
        unstable_entries: {entry: coordinates} for all unstable nodes in the
            phase diagram.
        ordering: Ordering of the phase diagram, given as a list ['Up',
            'Left','Right']

    Returns:
        (newlines, newstable_entries, newunstable_entries):
        - newlines is a list of list of coordinates for lines in the PD.
        - newstable_entries is a {coordinate : entry} for each stable node
        in the phase diagram. (Each coordinate can only have one
        stable phase)
        - newunstable_entries is a {entry: coordinates} for all unstable
        nodes in the phase diagram.
    """"""
    yup = -1000.0
    xleft = 1000.0
    xright = -1000.0

    for coord in stable_entries:
        if coord[0] > xright:
            xright = coord[0]
            nameright = stable_entries[coord].name
        if coord[0] < xleft:
            xleft = coord[0]
            nameleft = stable_entries[coord].name
        if coord[1] > yup:
            yup = coord[1]
            nameup = stable_entries[coord].name

    if (not nameup in ordering) or (not nameright in ordering) or \
            (not nameleft in ordering):
        raise ValueError(
            'Error in ordering_phase_diagram : \n""{up}"", ""{left}"" and ""{'
            'right}""'
            ' should be in ordering : {ord}'.format(up=nameup, left=nameleft,
                                                    right=nameright,
                                                    ord=ordering))

    cc = np.array([0.5, np.sqrt(3.0) / 6.0], np.float)

    if nameup == ordering[0]:
        if nameleft == ordering[1]:
            # The coordinates were already in the user ordering
            return lines, stable_entries, unstable_entries
        else:
            newlines = [[np.array(1.0 - x), y] for x, y in lines]
            newstable_entries = {(1.0 - c[0], c[1]): entry
                                 for c, entry in stable_entries.items()}
            newunstable_entries = {entry: (1.0 - c[0], c[1])
                                   for entry, c in
                                   unstable_entries.items()}
            return newlines, newstable_entries, newunstable_entries
    elif nameup == ordering[1]:
        if nameleft == ordering[2]:
            c120 = np.cos(2.0 * np.pi / 3.0)
            s120 = np.sin(2.0 * np.pi / 3.0)
            newlines = []
            for x, y in lines:
                newx = np.zeros_like(x)
                newy = np.zeros_like(y)
                for ii, xx in enumerate(x):
                    newx[ii] = c120 * (xx - cc[0]) - s120 * (y[ii] - cc[1]) + \
                               cc[0]
                    newy[ii] = s120 * (xx - cc[0]) + c120 * (y[ii] - cc[1]) + \
                               cc[1]
                newlines.append([newx, newy])
            newstable_entries = {
                (c120 * (c[0] - cc[0]) - s120 * (c[1] - cc[1]) + cc[0],
                 s120 * (c[0] - cc[0]) + c120 * (c[1] - cc[1]) + cc[1]): entry
                for c, entry in stable_entries.items()}
            newunstable_entries = {
                entry: (c120 * (c[0] - cc[0]) - s120 * (c[1] - cc[1]) + cc[0],
                        s120 * (c[0] - cc[0]) + c120 * (c[1] - cc[1]) + cc[1])
                for entry, c in unstable_entries.items()}
            return newlines, newstable_entries, newunstable_entries
        else:
            c120 = np.cos(2.0 * np.pi / 3.0)
            s120 = np.sin(2.0 * np.pi / 3.0)
            newlines = []
            for x, y in lines:
                newx = np.zeros_like(x)
                newy = np.zeros_like(y)
                for ii, xx in enumerate(x):
                    newx[ii] = -c120 * (xx - 1.0) - s120 * y[ii] + 1.0
                    newy[ii] = -s120 * (xx - 1.0) + c120 * y[ii]
                newlines.append([newx, newy])
            newstable_entries = {(-c120 * (c[0] - 1.0) - s120 * c[1] + 1.0,
                                  -s120 * (c[0] - 1.0) + c120 * c[1]): entry
                                 for c, entry in stable_entries.items()}
            newunstable_entries = {
                entry: (-c120 * (c[0] - 1.0) - s120 * c[1] + 1.0,
                        -s120 * (c[0] - 1.0) + c120 * c[1])
                for entry, c in unstable_entries.items()}
            return newlines, newstable_entries, newunstable_entries
    elif nameup == ordering[2]:
        if nameleft == ordering[0]:
            c240 = np.cos(4.0 * np.pi / 3.0)
            s240 = np.sin(4.0 * np.pi / 3.0)
            newlines = []
            for x, y in lines:
                newx = np.zeros_like(x)
                newy = np.zeros_like(y)
                for ii, xx in enumerate(x):
                    newx[ii] = c240 * (xx - cc[0]) - s240 * (y[ii] - cc[1]) + \
                               cc[0]
                    newy[ii] = s240 * (xx - cc[0]) + c240 * (y[ii] - cc[1]) + \
                               cc[1]
                newlines.append([newx, newy])
            newstable_entries = {
                (c240 * (c[0] - cc[0]) - s240 * (c[1] - cc[1]) + cc[0],
                 s240 * (c[0] - cc[0]) + c240 * (c[1] - cc[1]) + cc[1]): entry
                for c, entry in stable_entries.items()}
            newunstable_entries = {
                entry: (c240 * (c[0] - cc[0]) - s240 * (c[1] - cc[1]) + cc[0],
                        s240 * (c[0] - cc[0]) + c240 * (c[1] - cc[1]) + cc[1])
                for entry, c in unstable_entries.items()}
            return newlines, newstable_entries, newunstable_entries
        else:
            c240 = np.cos(4.0 * np.pi / 3.0)
            s240 = np.sin(4.0 * np.pi / 3.0)
            newlines = []
            for x, y in lines:
                newx = np.zeros_like(x)
                newy = np.zeros_like(y)
                for ii, xx in enumerate(x):
                    newx[ii] = -c240 * xx - s240 * y[ii]
                    newy[ii] = -s240 * xx + c240 * y[ii]
                newlines.append([newx, newy])
            newstable_entries = {(-c240 * c[0] - s240 * c[1],
                                  -s240 * c[0] + c240 * c[1]): entry
                                 for c, entry in stable_entries.items()}
            newunstable_entries = {entry: (-c240 * c[0] - s240 * c[1],
                                           -s240 * c[0] + c240 * c[1])
                                   for entry, c in unstable_entries.items()}
            return newlines, newstable_entries, newunstable_entries",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 3.9855247285886612, 'avgLineLength': 47.10204081632653, 'emptyLinesDensity': 0.04081632653061224, 'functionDefinitionDensity': 0.006802721088435374, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.4053748231966054}","def order_phase_diagram(lines, stable_entries, unstable_entries, ordering):
    
    yup = -1000.0
    xleft = 1000.0
    xright = -1000.0

    for coord in stable_entries:
        if coord[0] > xright:
            xright = coord[0]
            nameright = stable_entries[coord].name
        if coord[0] < xleft:
            xleft = coord[0]
            nameleft = stable_entries[coord].name
        if coord[1] > yup:
            yup = coord[1]
            nameup = stable_entries[coord].name

    if (not nameup in ordering) or (not nameright in ordering) or \
            (not nameleft in ordering):
        raise ValueError(
            'Error in ordering_phase_diagram : \n""{up}"", ""{left}"" and ""{'
            'right}""'
            ' should be in ordering : {ord}'.format(up=nameup, left=nameleft,
                                                    right=nameright,
                                                    ord=ordering))

    cc = np.array([0.5, np.sqrt(3.0) / 6.0], np.float)

    if nameup == ordering[0]:
        if nameleft == ordering[1]:
            
            return lines, stable_entries, unstable_entries
        else:
            newlines = [[np.array(1.0 - x), y] for x, y in lines]
            newstable_entries = {(1.0 - c[0], c[1]): entry
                                 for c, entry in stable_entries.items()}
            newunstable_entries = {entry: (1.0 - c[0], c[1])
                                   for entry, c in
                                   unstable_entries.items()}
            return newlines, newstable_entries, newunstable_entries
    elif nameup == ordering[1]:
        if nameleft == ordering[2]:
            c120 = np.cos(2.0 * np.pi / 3.0)
            s120 = np.sin(2.0 * np.pi / 3.0)
            newlines = []
            for x, y in lines:
                newx = np.zeros_like(x)
                newy = np.zeros_like(y)
                for ii, xx in enumerate(x):
                    newx[ii] = c120 * (xx - cc[0]) - s120 * (y[ii] - cc[1]) + \
                               cc[0]
                    newy[ii] = s120 * (xx - cc[0]) + c120 * (y[ii] - cc[1]) + \
                               cc[1]
                newlines.append([newx, newy])
            newstable_entries = {
                (c120 * (c[0] - cc[0]) - s120 * (c[1] - cc[1]) + cc[0],
                 s120 * (c[0] - cc[0]) + c120 * (c[1] - cc[1]) + cc[1]): entry
                for c, entry in stable_entries.items()}
            newunstable_entries = {
                entry: (c120 * (c[0] - cc[0]) - s120 * (c[1] - cc[1]) + cc[0],
                        s120 * (c[0] - cc[0]) + c120 * (c[1] - cc[1]) + cc[1])
                for entry, c in unstable_entries.items()}
            return newlines, newstable_entries, newunstable_entries
        else:
            c120 = np.cos(2.0 * np.pi / 3.0)
            s120 = np.sin(2.0 * np.pi / 3.0)
            newlines = []
            for x, y in lines:
                newx = np.zeros_like(x)
                newy = np.zeros_like(y)
                for ii, xx in enumerate(x):
                    newx[ii] = -c120 * (xx - 1.0) - s120 * y[ii] + 1.0
                    newy[ii] = -s120 * (xx - 1.0) + c120 * y[ii]
                newlines.append([newx, newy])
            newstable_entries = {(-c120 * (c[0] - 1.0) - s120 * c[1] + 1.0,
                                  -s120 * (c[0] - 1.0) + c120 * c[1]): entry
                                 for c, entry in stable_entries.items()}
            newunstable_entries = {
                entry: (-c120 * (c[0] - 1.0) - s120 * c[1] + 1.0,
                        -s120 * (c[0] - 1.0) + c120 * c[1])
                for entry, c in unstable_entries.items()}
            return newlines, newstable_entries, newunstable_entries
    elif nameup == ordering[2]:
        if nameleft == ordering[0]:
            c240 = np.cos(4.0 * np.pi / 3.0)
            s240 = np.sin(4.0 * np.pi / 3.0)
            newlines = []
            for x, y in lines:
                newx = np.zeros_like(x)
                newy = np.zeros_like(y)
                for ii, xx in enumerate(x):
                    newx[ii] = c240 * (xx - cc[0]) - s240 * (y[ii] - cc[1]) + \
                               cc[0]
                    newy[ii] = s240 * (xx - cc[0]) + c240 * (y[ii] - cc[1]) + \
                               cc[1]
                newlines.append([newx, newy])
            newstable_entries = {
                (c240 * (c[0] - cc[0]) - s240 * (c[1] - cc[1]) + cc[0],
                 s240 * (c[0] - cc[0]) + c240 * (c[1] - cc[1]) + cc[1]): entry
                for c, entry in stable_entries.items()}
            newunstable_entries = {
                entry: (c240 * (c[0] - cc[0]) - s240 * (c[1] - cc[1]) + cc[0],
                        s240 * (c[0] - cc[0]) + c240 * (c[1] - cc[1]) + cc[1])
                for entry, c in unstable_entries.items()}
            return newlines, newstable_entries, newunstable_entries
        else:
            c240 = np.cos(4.0 * np.pi / 3.0)
            s240 = np.sin(4.0 * np.pi / 3.0)
            newlines = []
            for x, y in lines:
                newx = np.zeros_like(x)
                newy = np.zeros_like(y)
                for ii, xx in enumerate(x):
                    newx[ii] = -c240 * xx - s240 * y[ii]
                    newy[ii] = -s240 * xx + c240 * y[ii]
                newlines.append([newx, newy])
            newstable_entries = {(-c240 * c[0] - s240 * c[1],
                                  -s240 * c[0] + c240 * c[1]): entry
                                 for c, entry in stable_entries.items()}
            newunstable_entries = {entry: (-c240 * c[0] - s240 * c[1],
                                           -s240 * c[0] + c240 * c[1])
                                   for entry, c in unstable_entries.items()}
            return newlines, newstable_entries, newunstable_entries"
"def reload(self):
        """"""Reload catalog if sufficient time has passed""""""
        if time.time() - self.updated > self.ttl:
            self.force_reload()",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.0, 'avgLineLength': 38.75, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.25, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2721518987341772}","def reload(self):
        
        if time.time() - self.updated > self.ttl:
            self.force_reload()"
"private void skipWhitespace() throws SAXException, IOException {
        // OK, do it the slow way.
        char c = readCh();
        while (isWhitespace(c)) {
            c = readCh();
        }
        unread(c);
    }",java,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 5.136363636363637, 'avgLineLength': 26.75, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 27.119999999999994, 'maxDecisionTokens': 2, 'whiteSpaceRatio': 0.37104072398190047}","private void skipWhitespace() throws SAXException, IOException {
        
        char c = readCh();
        while (isWhitespace(c)) {
            c = readCh();
        }
        unread(c);
    }"
"public <R> R removeMany(boolean nullify, int max_results, Predicate<T> filter,
                            Supplier<R> result_creator, BiConsumer<R,T> accumulator) {
        lock.lock();
        try {
            Remover<R> remover=new Remover<>(nullify, max_results, filter, result_creator, accumulator);
            forEach(hd+1, hr, remover);
            return remover.getResult();
        }
        finally {
            lock.unlock();
        }
    }",java,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 5.976190476190476, 'avgLineLength': 37.083333333333336, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.33771929824561403}","public <R> R removeMany(boolean nullify, int max_results, Predicate<T> filter,
                            Supplier<R> result_creator, BiConsumer<R,T> accumulator) {
        lock.lock();
        try {
            Remover<R> remover=new Remover<>(nullify, max_results, filter, result_creator, accumulator);
            forEach(hd+1, hr, remover);
            return remover.getResult();
        }
        finally {
            lock.unlock();
        }
    }"
"public static Response getDeleteResponse(App app, ParaObject content) {
		try (final Metrics.Context context = Metrics.time(app == null ? null : app.getAppid(),
				RestUtils.class, ""crud"", ""delete"")) {
			if (app != null && content != null && content.getId() != null && content.getAppid() != null) {
				if (checkImplicitAppPermissions(app, content) && checkIfUserCanModifyObject(app, content)) {
					content.setAppid(isNotAnApp(content.getType()) ? app.getAppIdentifier() : app.getAppid());
					content.delete();
					return Response.ok().build();
				}
				return getStatusResponse(Response.Status.BAD_REQUEST);
			}
			return getStatusResponse(Response.Status.NOT_FOUND);
		}
	}",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 7.059701492537314, 'avgLineLength': 47.92857142857143, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.07142857142857142, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 6, 'whiteSpaceRatio': 0.15789473684210525}","public static Response getDeleteResponse(App app, ParaObject content) {
		try (final Metrics.Context context = Metrics.time(app == null ? null : app.getAppid(),
				RestUtils.class, ""crud"", ""delete"")) {
			if (app != null && content != null && content.getId() != null && content.getAppid() != null) {
				if (checkImplicitAppPermissions(app, content) && checkIfUserCanModifyObject(app, content)) {
					content.setAppid(isNotAnApp(content.getType()) ? app.getAppIdentifier() : app.getAppid());
					content.delete();
					return Response.ok().build();
				}
				return getStatusResponse(Response.Status.BAD_REQUEST);
			}
			return getStatusResponse(Response.Status.NOT_FOUND);
		}
	}"
"def fetchUserInfo(self, *user_ids):
        """"""
        Get users' info from IDs, unordered

        .. warning::
            Sends two requests, to fetch all available info!

        :param user_ids: One or more user ID(s) to query
        :return: :class:`models.User` objects, labeled by their ID
        :rtype: dict
        :raises: FBchatException if request failed
        """"""
        threads = self.fetchThreadInfo(*user_ids)
        users = {}
        for id_, thread in threads.items():
            if thread.type == ThreadType.USER:
                users[id_] = thread
            else:
                raise FBchatUserError(""Thread {} was not a user"".format(thread))

        return users",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.2105263157894735, 'avgLineLength': 32.38095238095238, 'emptyLinesDensity': 0.14285714285714285, 'functionDefinitionDensity': 0.047619047619047616, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.34}","def fetchUserInfo(self, *user_ids):
        
        threads = self.fetchThreadInfo(*user_ids)
        users = {}
        for id_, thread in threads.items():
            if thread.type == ThreadType.USER:
                users[id_] = thread
            else:
                raise FBchatUserError(""Thread {} was not a user"".format(thread))

        return users"
"def create_actor_hexahedron(grid, color, **kwargs):
    """""" Creates a VTK actor for rendering voxels using hexahedron elements.

    :param grid: grid
    :type grid: ndarray
    :param color: actor color
    :type color: list
    :return: a VTK actor
    :rtype: vtkActor
    """"""
    # Keyword arguments
    array_name = kwargs.get('name', """")
    array_index = kwargs.get('index', 0)

    # Create hexahedron elements
    points = vtk.vtkPoints()
    hexarray = vtk.vtkCellArray()
    for j, pt in enumerate(grid):
        tmp = vtk.vtkHexahedron()
        fb = pt[0]
        for i, v in enumerate(fb):
            points.InsertNextPoint(v)
            tmp.GetPointIds().SetId(i, i + (j * 8))
        ft = pt[-1]
        for i, v in enumerate(ft):
            points.InsertNextPoint(v)
            tmp.GetPointIds().SetId(i + 4, i + 4 + (j * 8))
        hexarray.InsertNextCell(tmp)

    # Create an unstructured grid object and add points & hexahedron elements
    ugrid = vtk.vtkUnstructuredGrid()
    ugrid.SetPoints(points)
    ugrid.SetCells(tmp.GetCellType(), hexarray)
    # ugrid.InsertNextCell(tmp.GetCellType(), tmp.GetPointIds())

    # Map unstructured grid to the graphics primitives
    mapper = vtk.vtkDataSetMapper()
    mapper.SetInputDataObject(ugrid)
    mapper.SetArrayName(array_name)
    mapper.SetArrayId(array_index)

    # Create an actor and set its properties
    actor = vtk.vtkActor()
    actor.SetMapper(mapper)
    actor.GetProperty().SetColor(*color)

    # Return the actor
    return actor",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.64367816091954, 'avgLineLength': 30.791666666666668, 'emptyLinesDensity': 0.125, 'functionDefinitionDensity': 0.020833333333333332, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.24786885245901638}","def create_actor_hexahedron(grid, color, **kwargs):
    
    
    array_name = kwargs.get('name', """")
    array_index = kwargs.get('index', 0)

    
    points = vtk.vtkPoints()
    hexarray = vtk.vtkCellArray()
    for j, pt in enumerate(grid):
        tmp = vtk.vtkHexahedron()
        fb = pt[0]
        for i, v in enumerate(fb):
            points.InsertNextPoint(v)
            tmp.GetPointIds().SetId(i, i + (j * 8))
        ft = pt[-1]
        for i, v in enumerate(ft):
            points.InsertNextPoint(v)
            tmp.GetPointIds().SetId(i + 4, i + 4 + (j * 8))
        hexarray.InsertNextCell(tmp)

    
    ugrid = vtk.vtkUnstructuredGrid()
    ugrid.SetPoints(points)
    ugrid.SetCells(tmp.GetCellType(), hexarray)
    

    
    mapper = vtk.vtkDataSetMapper()
    mapper.SetInputDataObject(ugrid)
    mapper.SetArrayName(array_name)
    mapper.SetArrayId(array_index)

    
    actor = vtk.vtkActor()
    actor.SetMapper(mapper)
    actor.GetProperty().SetColor(*color)

    
    return actor"
"public static Point3D_F64 transfer_1_to_3(TrifocalTensor T , Point2D_F64 x1 , Vector3D_F64 l2 ,
											  @Nullable Point3D_F64 x3 )
	{
		if( x3 == null )
			x3 = new Point3D_F64();

		GeometryMath_F64.multTran(T.T1,l2,x3);
		// storage solution here to avoid the need to declare a temporary variable
		double xx = x3.x * x1.x;
		double yy = x3.y * x1.x;
		double zz = x3.z * x1.x;
		GeometryMath_F64.multTran(T.T2,l2,x3);
		xx += x3.x * x1.y;
		yy += x3.y * x1.y;
		zz += x3.z * x1.y;
		GeometryMath_F64.multTran(T.T3,l2,x3);
		x3.x = xx + x3.x;
		x3.y = yy + x3.y;
		x3.z = zz + x3.z;

		return x3;
		// Commented out code is closer to tensor notation. The above was derived from it
//		for (int i = 0; i < 3; i++) {
//			DMatrixRMaj t = T.T1;
//
//			double vx;
//			switch( i ) {
//				case 0: vx = x.x; break;
//				case 1: vx = x.y; break;
//				case 2: vx = 1; break;
//				default: throw new RuntimeException(""Egads"");
//			}

//			sumX += vx*(l.x*t.get(0,0)+l.y*t.get(1,0)+l.z*t.get(2,0));
//			sumY += vx*(l.x*t.get(0,1)+l.y*t.get(1,1)+l.z*t.get(2,1));
//			sumZ += vx*(l.x*t.get(0,2)+l.y*t.get(1,2)+l.z*t.get(2,2));
//		}
	}",java,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 3.085714285714286, 'avgLineLength': 28.973684210526315, 'emptyLinesDensity': 0.07894736842105263, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 1.4657142857142924, 'maxDecisionTokens': 6, 'whiteSpaceRatio': 0.22407732864674867}","public static Point3D_F64 transfer_1_to_3(TrifocalTensor T , Point2D_F64 x1 , Vector3D_F64 l2 ,
											  @Nullable Point3D_F64 x3 )
	{
		if( x3 == null )
			x3 = new Point3D_F64();

		GeometryMath_F64.multTran(T.T1,l2,x3);
		
		double xx = x3.x * x1.x;
		double yy = x3.y * x1.x;
		double zz = x3.z * x1.x;
		GeometryMath_F64.multTran(T.T2,l2,x3);
		xx += x3.x * x1.y;
		yy += x3.y * x1.y;
		zz += x3.z * x1.y;
		GeometryMath_F64.multTran(T.T3,l2,x3);
		x3.x = xx + x3.x;
		x3.y = yy + x3.y;
		x3.z = zz + x3.z;

		return x3;
		















	}"
"@Override
  public boolean isValid(int timeout) throws SQLException {

    int initialTimeout = -1;
    try {
      initialTimeout = socket.getSoTimeout();
      if (initialTimeout == 0) {
        socket.setSoTimeout(timeout);
      }
      if (isMasterConnection() && !galeraAllowedStates.isEmpty()) {
        //this is a galera node.
        //checking not only that node is responding, but that galera state is allowed.
        Results results = new Results();
        executeQuery(true, results, CHECK_GALERA_STATE_QUERY);
        results.commandEnd();
        ResultSet rs = results.getResultSet();

        return rs != null && rs.next() && galeraAllowedStates.contains(rs.getString(2));
      }

      return ping();

    } catch (SocketException socketException) {
      logger.trace(""Connection is not valid"", socketException);
      connected = false;
      return false;
    } finally {

      //set back initial socket timeout
      try {
        if (initialTimeout != -1) {
          socket.setSoTimeout(initialTimeout);
        }
      } catch (SocketException socketException) {
        logger.warn(""Could not set socket timeout back to "" + initialTimeout, socketException);
        connected = false;
        //eat
      }
    }
  }",java,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 6.849557522123894, 'avgLineLength': 30.225, 'emptyLinesDensity': 0.125, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 2, 'whiteSpaceRatio': 0.27724358974358976}","@Override
  public boolean isValid(int timeout) throws SQLException {

    int initialTimeout = -1;
    try {
      initialTimeout = socket.getSoTimeout();
      if (initialTimeout == 0) {
        socket.setSoTimeout(timeout);
      }
      if (isMasterConnection() && !galeraAllowedStates.isEmpty()) {
        
        
        Results results = new Results();
        executeQuery(true, results, CHECK_GALERA_STATE_QUERY);
        results.commandEnd();
        ResultSet rs = results.getResultSet();

        return rs != null && rs.next() && galeraAllowedStates.contains(rs.getString(2));
      }

      return ping();

    } catch (SocketException socketException) {
      logger.trace(""Connection is not valid"", socketException);
      connected = false;
      return false;
    } finally {

      
      try {
        if (initialTimeout != -1) {
          socket.setSoTimeout(initialTimeout);
        }
      } catch (SocketException socketException) {
        logger.warn(""Could not set socket timeout back to "" + initialTimeout, socketException);
        connected = false;
        
      }
    }
  }"
"def _RequestBodyFromData(data):
    """"""Gets request body from data.

    When `data` is dict and list into unicode string; otherwise return `data`
    without making any change.

    :param (str, unicode, file-like stream object, dict, list or None) data:

    :rtype:
        str, unicode, file-like stream object, or None

    """"""
    if isinstance(data, six.string_types) or _IsReadableStream(data):
        return data
    elif isinstance(data, (dict, list, tuple)):
        
        json_dumped = json.dumps(data, separators=(',',':'))

        if six.PY2:
            return json_dumped.decode('utf-8')
        else:
            return json_dumped
    return None",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.291139240506329, 'avgLineLength': 28.130434782608695, 'emptyLinesDensity': 0.2608695652173913, 'functionDefinitionDensity': 0.043478260869565216, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2705530642750374}","def _RequestBodyFromData(data):
    
    if isinstance(data, six.string_types) or _IsReadableStream(data):
        return data
    elif isinstance(data, (dict, list, tuple)):
        
        json_dumped = json.dumps(data, separators=(',',':'))

        if six.PY2:
            return json_dumped.decode('utf-8')
        else:
            return json_dumped
    return None"
"protected Object doGetTransaction() {
        Object dataSourceTransactionObject = super.doGetTransaction();
        Object contextSourceTransactionObject = ldapManagerDelegate
                .doGetTransaction();

        return new ContextSourceAndHibernateTransactionObject(
                contextSourceTransactionObject, dataSourceTransactionObject);
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 16.5, 'avgLineLength': 44.25, 'emptyLinesDensity': 0.125, 'functionDefinitionDensity': 0.125, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2188365650969529}","protected Object doGetTransaction() {
        Object dataSourceTransactionObject = super.doGetTransaction();
        Object contextSourceTransactionObject = ldapManagerDelegate
                .doGetTransaction();

        return new ContextSourceAndHibernateTransactionObject(
                contextSourceTransactionObject, dataSourceTransactionObject);
    }"
"public void setPrimitive(Type type, int val) {
        if (type.hasValue()) {
            this.type = type;
            this.value = val;
            this.left = null;
            this.right = null;
            this.query = null;
        } else {
            throw new IllegalArgumentException(""Value provided for non-value ""
                                               + ""expression type!"");
        }
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.166666666666667, 'avgLineLength': 33.333333333333336, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.08333333333333333, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 2, 'whiteSpaceRatio': 0.45255474452554745}","public void setPrimitive(Type type, int val) {
        if (type.hasValue()) {
            this.type = type;
            this.value = val;
            this.left = null;
            this.right = null;
            this.query = null;
        } else {
            throw new IllegalArgumentException(""Value provided for non-value ""
                                               + ""expression type!"");
        }
    }"
"private int getMaxOccurence(double massTo, int element_pos, int[] matrix, List<IIsotope> isoToCond_new) {
        double massIn = isoToCond_new.get(element_pos).getExactMass();
        double massToM = massTo;
        for (int i = 0; i < matrix.length; i++)
            if (i != element_pos) if (matrix[i] != 0) massToM -= isoToCond_new.get(i).getExactMass() * matrix[i];

        int value = (int) ((massToM + 1) / massIn);
        return value;
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.490196078431373, 'avgLineLength': 49.333333333333336, 'emptyLinesDensity': 0.1111111111111111, 'functionDefinitionDensity': 0.1111111111111111, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 7, 'whiteSpaceRatio': 0.2411504424778761}","private int getMaxOccurence(double massTo, int element_pos, int[] matrix, List<IIsotope> isoToCond_new) {
        double massIn = isoToCond_new.get(element_pos).getExactMass();
        double massToM = massTo;
        for (int i = 0; i < matrix.length; i++)
            if (i != element_pos) if (matrix[i] != 0) massToM -= isoToCond_new.get(i).getExactMass() * matrix[i];

        int value = (int) ((massToM + 1) / massIn);
        return value;
    }"
"protected PredicateLevelProposal proposeForGroupingMap(
            ImmutableMultimap<ImmutableList<VariableOrGroundTerm>, ExtensionalDataNode> groupingMap)
    throws AtomUnificationException {

        ImmutableCollection<Collection<ExtensionalDataNode>> dataNodeGroups = groupingMap.asMap().values();

        try {
            /*
             * Collection of unifying substitutions
             */
            ImmutableSet<ImmutableSubstitution<VariableOrGroundTerm>> unifyingSubstitutions =
                    dataNodeGroups.stream()
                            .filter(g -> g.size() > 1)
                            .map(redundantNodes -> {
                                    try {
                                        return unifyRedundantNodes(redundantNodes);
                                    } catch (AtomUnificationException e) {
                                        throw new AtomUnificationRuntimeException(e);
                                    }
                            })
                            .filter(s -> !s.isEmpty())
                            .collect(ImmutableCollectors.toSet());
            /*
             * All the nodes that have been at least once dominated (--> could thus be removed).
             *
             * Not parallellizable
             */
            ImmutableSet<ExtensionalDataNode> removableNodes = ImmutableSet.copyOf(dataNodeGroups.stream()
                    .filter(sameRowDataNodes -> sameRowDataNodes.size() > 1)
                    .reduce(
                            new Dominance(),
                            Dominance::update,
                            (dom1, dom2) -> {
                                throw new IllegalStateException(""Cannot be run in parallel"");
                            })
                    .getRemovalNodes());

            return new PredicateLevelProposal(unifyingSubstitutions, removableNodes);

            /*
             * Trick: rethrow the exception
              */
        } catch (AtomUnificationRuntimeException e) {
            throw e.checkedException;
        }
    }",java,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 9.142857142857142, 'avgLineLength': 44.5, 'emptyLinesDensity': 0.08695652173913043, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.4378585086042065}","protected PredicateLevelProposal proposeForGroupingMap(
            ImmutableMultimap<ImmutableList<VariableOrGroundTerm>, ExtensionalDataNode> groupingMap)
    throws AtomUnificationException {

        ImmutableCollection<Collection<ExtensionalDataNode>> dataNodeGroups = groupingMap.asMap().values();

        try {
            
            ImmutableSet<ImmutableSubstitution<VariableOrGroundTerm>> unifyingSubstitutions =
                    dataNodeGroups.stream()
                            .filter(g -> g.size() > 1)
                            .map(redundantNodes -> {
                                    try {
                                        return unifyRedundantNodes(redundantNodes);
                                    } catch (AtomUnificationException e) {
                                        throw new AtomUnificationRuntimeException(e);
                                    }
                            })
                            .filter(s -> !s.isEmpty())
                            .collect(ImmutableCollectors.toSet());
            
            ImmutableSet<ExtensionalDataNode> removableNodes = ImmutableSet.copyOf(dataNodeGroups.stream()
                    .filter(sameRowDataNodes -> sameRowDataNodes.size() > 1)
                    .reduce(
                            new Dominance(),
                            Dominance::update,
                            (dom1, dom2) -> {
                                throw new IllegalStateException(""Cannot be run in parallel"");
                            })
                    .getRemovalNodes());

            return new PredicateLevelProposal(unifyingSubstitutions, removableNodes);

            
        } catch (AtomUnificationRuntimeException e) {
            throw e.checkedException;
        }
    }"
"def _compute_layout_validator(self):
    """"""Computes self._layout_validator.""""""
    self._layout_validator = valid_layouts.LayoutValidator(self.mtf_graph,
                                                           self.mesh_shape)",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 9.785714285714286, 'avgLineLength': 56.75, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.25, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3217391304347826}","def _compute_layout_validator(self):
    
    self._layout_validator = valid_layouts.LayoutValidator(self.mtf_graph,
                                                           self.mesh_shape)"
"public MoneyAmountStyle withDecimalPointCharacter(Character decimalPointCharacter) {
        int dpVal = (decimalPointCharacter == null ? -1 : decimalPointCharacter);
        if (dpVal == this.decimalPointCharacter) {
            return this;
        }
        return new MoneyAmountStyle(
                zeroCharacter,
                positiveCharacter, negativeCharacter,
                dpVal, groupingStyle,
                groupingCharacter, groupingSize, extendedGroupingSize, forceDecimalPoint, absValue);
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 11.266666666666667, 'avgLineLength': 47.18181818181818, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.09090909090909091, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 3, 'whiteSpaceRatio': 0.29867674858223064}","public MoneyAmountStyle withDecimalPointCharacter(Character decimalPointCharacter) {
        int dpVal = (decimalPointCharacter == null ? -1 : decimalPointCharacter);
        if (dpVal == this.decimalPointCharacter) {
            return this;
        }
        return new MoneyAmountStyle(
                zeroCharacter,
                positiveCharacter, negativeCharacter,
                dpVal, groupingStyle,
                groupingCharacter, groupingSize, extendedGroupingSize, forceDecimalPoint, absValue);
    }"
void reset_arrays() { ile = 0; },cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.0, 'avgLineLength': 32.0, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 33.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.1875}",void reset_arrays() { ile = 0; }
"def StaticAdd(cls,
                collection_urn,
                rdf_value,
                timestamp=None,
                suffix=None,
                mutation_pool=None):
    """"""Adds an rdf value to a collection.

    Adds an rdf value to a collection. Does not require that the collection be
    open. NOTE: The caller is responsible for ensuring that the collection
    exists and is of the correct type.

    Args:
      collection_urn: The urn of the collection to add to.
      rdf_value: The rdf value to add to the collection. If this value is not
        GrrMessage, it will be wrapped into GrrMessage (later when collection is
        iterated, this value will still be returned wrapped in GrrMessage).
      timestamp: The timestamp (in microseconds) to store the rdf value at.
        Defaults to the current time.
      suffix: A 'fractional timestamp' suffix to reduce the chance of
        collisions. Defaults to a random number.
      mutation_pool: A MutationPool object to write to.

    Returns:
      The pair (timestamp, suffix) which identifies the value within the
      collection.

    Raises:
      ValueError: rdf_value has unexpected type.

    """"""
    if rdf_value is None:
      raise ValueError(""Can't add None to MultiTypeCollection"")
    if mutation_pool is None:
      raise ValueError(""Mutation pool can't be none."")

    if not isinstance(rdf_value, rdf_flows.GrrMessage):
      rdf_value = rdf_flows.GrrMessage(payload=rdf_value)

    value_type = rdf_value.args_rdf_name or rdf_flows.GrrMessage.__name__

    # In order to make this fast, we never actually generate the
    # subcollections, we just use them. This means that we cannot use
    # ListChildren to get all the items stored in this
    # MultiTypeCollection.
    subpath = collection_urn.Add(value_type)
    sequential_collection.GrrMessageCollection.StaticAdd(
        subpath,
        rdf_value,
        timestamp=timestamp,
        suffix=suffix,
        mutation_pool=mutation_pool)

    mutation_pool.CollectionAddStoredTypeIndex(collection_urn, value_type)",python,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 5.844897959183673, 'avgLineLength': 37.31481481481482, 'emptyLinesDensity': 0.16666666666666666, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2562862669245648}","def StaticAdd(cls,
                collection_urn,
                rdf_value,
                timestamp=None,
                suffix=None,
                mutation_pool=None):
    
    if rdf_value is None:
      raise ValueError(""Can't add None to MultiTypeCollection"")
    if mutation_pool is None:
      raise ValueError(""Mutation pool can't be none."")

    if not isinstance(rdf_value, rdf_flows.GrrMessage):
      rdf_value = rdf_flows.GrrMessage(payload=rdf_value)

    value_type = rdf_value.args_rdf_name or rdf_flows.GrrMessage.__name__

    
    
    
    
    subpath = collection_urn.Add(value_type)
    sequential_collection.GrrMessageCollection.StaticAdd(
        subpath,
        rdf_value,
        timestamp=timestamp,
        suffix=suffix,
        mutation_pool=mutation_pool)

    mutation_pool.CollectionAddStoredTypeIndex(collection_urn, value_type)"
"def _get_ancestors_of(self, obs_nodes_list):
        """"""
        Returns a dictionary of all ancestors of all the observed nodes including the
        node itself.
        Parameters
        ----------
        obs_nodes_list: string, list-type
            name of all the observed nodes
        Examples
        --------
        >>> from pgmpy.base import DAG
        >>> model = DAG([('D', 'G'), ('I', 'G'), ('G', 'L'),
        ...                        ('I', 'L')])
        >>> model._get_ancestors_of('G')
        {'D', 'G', 'I'}
        >>> model._get_ancestors_of(['G', 'I'])
        {'D', 'G', 'I'}
        """"""
        if not isinstance(obs_nodes_list, (list, tuple)):
            obs_nodes_list = [obs_nodes_list]

        for node in obs_nodes_list:
            if node not in self.nodes():
                raise ValueError('Node {s} not in not in graph'.format(s=node))

        ancestors_list = set()
        nodes_list = set(obs_nodes_list)
        while nodes_list:
            node = nodes_list.pop()
            if node not in ancestors_list:
                nodes_list.update(self.predecessors(node))
            ancestors_list.add(node)
        return ancestors_list",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.333333333333333, 'avgLineLength': 34.878787878787875, 'emptyLinesDensity': 0.06060606060606061, 'functionDefinitionDensity': 0.030303030303030304, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.34657650042265425}","def _get_ancestors_of(self, obs_nodes_list):
        
        if not isinstance(obs_nodes_list, (list, tuple)):
            obs_nodes_list = [obs_nodes_list]

        for node in obs_nodes_list:
            if node not in self.nodes():
                raise ValueError('Node {s} not in not in graph'.format(s=node))

        ancestors_list = set()
        nodes_list = set(obs_nodes_list)
        while nodes_list:
            node = nodes_list.pop()
            if node not in ancestors_list:
                nodes_list.update(self.predecessors(node))
            ancestors_list.add(node)
        return ancestors_list"
"def delete_chat_sticker_set(self, chat_id):
        """"""
        Use this method to delete a group sticker set from a supergroup. The bot must be an administrator in the chat
        for this to work and must have the appropriate admin rights. Use the field can_set_sticker_set
        optionally returned in getChat requests to check if the bot can use this method. Returns True on success.
        :param chat_id:	Unique identifier for the target chat or username of the target supergroup
        (in the format @supergroupusername)
        :return:
        """"""
        result = apihelper.delete_chat_sticker_set(self.token, chat_id)
        return result",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.482352941176471, 'avgLineLength': 58.72727272727273, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.09090909090909091, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.24847560975609756}","def delete_chat_sticker_set(self, chat_id):
        
        result = apihelper.delete_chat_sticker_set(self.token, chat_id)
        return result"
"String getResponseToken(String responseInbox) {
        int len = getRespInboxLength();
        if (responseInbox.length() <= len) {
            return responseInbox;
        }
        return responseInbox.substring(len);
    }",java,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 8.176470588235293, 'avgLineLength': 32.42857142857143, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 2, 'whiteSpaceRatio': 0.3090128755364807}","String getResponseToken(String responseInbox) {
        int len = getRespInboxLength();
        if (responseInbox.length() <= len) {
            return responseInbox;
        }
        return responseInbox.substring(len);
    }"
"def plot_points(points, lattice=None, coords_are_cartesian=False, fold=False,
                ax=None, **kwargs):
    """"""
    Adds Points to a matplotlib Axes

    Args:
        points: list of coordinates
        lattice: Lattice object used to convert from reciprocal to cartesian coordinates
        coords_are_cartesian: Set to True if you are providing
            coordinates in cartesian coordinates. Defaults to False.
            Requires lattice if False.
        fold: whether the points should be folded inside the first Brillouin Zone.
            Defaults to False. Requires lattice if True.
        ax: matplotlib :class:`Axes` or None if a new figure should be created.
        kwargs: kwargs passed to the matplotlib function 'scatter'. Color defaults to blue

    Returns:
        matplotlib figure and matplotlib ax
    """"""
    ax, fig, plt = get_ax3d_fig_plt(ax)

    if ""color"" not in kwargs:
        kwargs[""color""] = ""b""

    if (not coords_are_cartesian or fold) and lattice is None:
        raise ValueError(
            ""coords_are_cartesian False or fold True require the lattice"")

    for p in points:

        if fold:
            p = fold_point(p, lattice,
                           coords_are_cartesian=coords_are_cartesian)

        elif not coords_are_cartesian:
            p = lattice.get_cartesian_coords(p)

        ax.scatter(*p, **kwargs)

    return fig, ax",python,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 5.60248447204969, 'avgLineLength': 34.0, 'emptyLinesDensity': 0.225, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2944960686204432}","def plot_points(points, lattice=None, coords_are_cartesian=False, fold=False,
                ax=None, **kwargs):
    
    ax, fig, plt = get_ax3d_fig_plt(ax)

    if ""color"" not in kwargs:
        kwargs[""color""] = ""b""

    if (not coords_are_cartesian or fold) and lattice is None:
        raise ValueError(
            ""coords_are_cartesian False or fold True require the lattice"")

    for p in points:

        if fold:
            p = fold_point(p, lattice,
                           coords_are_cartesian=coords_are_cartesian)

        elif not coords_are_cartesian:
            p = lattice.get_cartesian_coords(p)

        ax.scatter(*p, **kwargs)

    return fig, ax"
"def query(self, query, time_precision='s', chunked=False):
        """"""Query data from the influxdb v0.8 database.

        :param time_precision: [Optional, default 's'] Either 's', 'm', 'ms'
            or 'u'.
        :param chunked: [Optional, default=False] True if the data shall be
            retrieved in chunks, False otherwise.
        """"""
        return self._query(query, time_precision=time_precision,
                           chunked=chunked)",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.352941176470588, 'avgLineLength': 44.9, 'emptyLinesDensity': 0.1, 'functionDefinitionDensity': 0.1, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2925764192139738}","def query(self, query, time_precision='s', chunked=False):
        
        return self._query(query, time_precision=time_precision,
                           chunked=chunked)"
"def set(self, **kwargs):
        """"""
        Set properties
        """"""
        for name, value in kwargs.items():
            if hasattr(self, name):
                setattr(self, name, value)
            else:
                raise AttributeError(
                    ""{!r} object has no attribute {}"".format(
                        self.__class__.__name__,
                        name))",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.03030303030303, 'avgLineLength': 31.666666666666668, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.08333333333333333, 'maintainabilityIndex': 1.5666666666666345, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.47058823529411764}","def set(self, **kwargs):
        
        for name, value in kwargs.items():
            if hasattr(self, name):
                setattr(self, name, value)
            else:
                raise AttributeError(
                    ""{!r} object has no attribute {}"".format(
                        self.__class__.__name__,
                        name))"
"def get_expanded_path(self, path):
        """"""
        expands a path that starts with an ~ to an absolute path
        :param path:
        :return:
        """"""
        if path.startswith('~'):
            return os.path.expanduser('~') + path[1:]
        else:
            return path",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.8, 'avgLineLength': 27.7, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.1, 'maintainabilityIndex': 22.28, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3776223776223776}","def get_expanded_path(self, path):
        
        if path.startswith('~'):
            return os.path.expanduser('~') + path[1:]
        else:
            return path"
"def get_symbol_returns_from_yahoo(symbol, start=None, end=None):
    """"""
    Wrapper for pandas.io.data.get_data_yahoo().
    Retrieves prices for symbol from yahoo and computes returns
    based on adjusted closing prices.

    Parameters
    ----------
    symbol : str
        Symbol name to load, e.g. 'SPY'
    start : pandas.Timestamp compatible, optional
        Start date of time period to retrieve
    end : pandas.Timestamp compatible, optional
        End date of time period to retrieve

    Returns
    -------
    pandas.DataFrame
        Returns of symbol in requested period.
    """"""

    try:
        px = web.get_data_yahoo(symbol, start=start, end=end)
        px['date'] = pd.to_datetime(px['date'])
        px.set_index('date', drop=False, inplace=True)
        rets = px[['adjclose']].pct_change().dropna()
    except Exception as e:
        warnings.warn(
            'Yahoo Finance read failed: {}, falling back to Google'.format(e),
            UserWarning)
        px = web.get_data_google(symbol, start=start, end=end)
        rets = px[['Close']].pct_change().dropna()

    rets.index = rets.index.tz_localize(""UTC"")
    rets.columns = [symbol]
    return rets",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.420289855072464, 'avgLineLength': 32.05555555555556, 'emptyLinesDensity': 0.1111111111111111, 'functionDefinitionDensity': 0.027777777777777776, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2523128679562658}","def get_symbol_returns_from_yahoo(symbol, start=None, end=None):
    

    try:
        px = web.get_data_yahoo(symbol, start=start, end=end)
        px['date'] = pd.to_datetime(px['date'])
        px.set_index('date', drop=False, inplace=True)
        rets = px[['adjclose']].pct_change().dropna()
    except Exception as e:
        warnings.warn(
            'Yahoo Finance read failed: {}, falling back to Google'.format(e),
            UserWarning)
        px = web.get_data_google(symbol, start=start, end=end)
        rets = px[['Close']].pct_change().dropna()

    rets.index = rets.index.tz_localize(""UTC"")
    rets.columns = [symbol]
    return rets"
"def _handle_eio_message(self, sid, data):
        """"""Dispatch Engine.IO messages.""""""
        if sid in self._binary_packet:
            pkt = self._binary_packet[sid]
            if pkt.add_attachment(data):
                del self._binary_packet[sid]
                if pkt.packet_type == packet.BINARY_EVENT:
                    self._handle_event(sid, pkt.namespace, pkt.id, pkt.data)
                else:
                    self._handle_ack(sid, pkt.namespace, pkt.id, pkt.data)
        else:
            pkt = packet.Packet(encoded_packet=data)
            if pkt.packet_type == packet.CONNECT:
                self._handle_connect(sid, pkt.namespace)
            elif pkt.packet_type == packet.DISCONNECT:
                self._handle_disconnect(sid, pkt.namespace)
            elif pkt.packet_type == packet.EVENT:
                self._handle_event(sid, pkt.namespace, pkt.id, pkt.data)
            elif pkt.packet_type == packet.ACK:
                self._handle_ack(sid, pkt.namespace, pkt.id, pkt.data)
            elif pkt.packet_type == packet.BINARY_EVENT or \
                    pkt.packet_type == packet.BINARY_ACK:
                self._binary_packet[sid] = pkt
            elif pkt.packet_type == packet.ERROR:
                raise ValueError('Unexpected ERROR packet.')
            else:
                raise ValueError('Unknown packet type.')",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.843283582089552, 'avgLineLength': 49.7037037037037, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.037037037037037035, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3296783625730994}","def _handle_eio_message(self, sid, data):
        
        if sid in self._binary_packet:
            pkt = self._binary_packet[sid]
            if pkt.add_attachment(data):
                del self._binary_packet[sid]
                if pkt.packet_type == packet.BINARY_EVENT:
                    self._handle_event(sid, pkt.namespace, pkt.id, pkt.data)
                else:
                    self._handle_ack(sid, pkt.namespace, pkt.id, pkt.data)
        else:
            pkt = packet.Packet(encoded_packet=data)
            if pkt.packet_type == packet.CONNECT:
                self._handle_connect(sid, pkt.namespace)
            elif pkt.packet_type == packet.DISCONNECT:
                self._handle_disconnect(sid, pkt.namespace)
            elif pkt.packet_type == packet.EVENT:
                self._handle_event(sid, pkt.namespace, pkt.id, pkt.data)
            elif pkt.packet_type == packet.ACK:
                self._handle_ack(sid, pkt.namespace, pkt.id, pkt.data)
            elif pkt.packet_type == packet.BINARY_EVENT or \
                    pkt.packet_type == packet.BINARY_ACK:
                self._binary_packet[sid] = pkt
            elif pkt.packet_type == packet.ERROR:
                raise ValueError('Unexpected ERROR packet.')
            else:
                raise ValueError('Unknown packet type.')"
"int QueryMax(int L, int R) {

 if (L > R) return 0;

 int k = len[R - L + 1];

 return max(mx[L][k], mx[R - (1 << k) + 1][k]);
  }",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 2.142857142857143, 'avgLineLength': 15.375, 'emptyLinesDensity': 0.375, 'functionDefinitionDensity': 16.375, 'maintainabilityIndex': 5.66999999999998, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2846153846153846}","int QueryMax(int L, int R) {

 if (L > R) return 0;

 int k = len[R - L + 1];

 return max(mx[L][k], mx[R - (1 << k) + 1][k]);
  }"
"private static void dumpConfiguration(Writer writer) throws IOException {
    Configuration.dumpConfiguration(new JobConf(), writer);
    writer.write(""\n"");
    // get the QueueManager configuration properties
    QueueManager.dumpConfiguration(writer);
    writer.write(""\n"");
  }",java,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 7.7407407407407405, 'avgLineLength': 39.42857142857143, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.14893617021276595}","private static void dumpConfiguration(Writer writer) throws IOException {
    Configuration.dumpConfiguration(new JobConf(), writer);
    writer.write(""\n"");
    
    QueueManager.dumpConfiguration(writer);
    writer.write(""\n"");
  }"
"def qft_circuit(qubits: Qubits) -> Circuit:
    """"""Returns the Quantum Fourier Transform circuit""""""
    # Kudos: Adapted from Rigetti Grove, grove/qft/fourier.py

    N = len(qubits)
    circ = Circuit()
    for n0 in range(N):
        q0 = qubits[n0]
        circ += H(q0)
        for n1 in range(n0+1, N):
            q1 = qubits[n1]
            angle = pi / 2 ** (n1-n0)
            circ += CPHASE(angle, q1, q0)
    circ.extend(reversal_circuit(qubits))
    return circ",python,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 4.32258064516129, 'avgLineLength': 30.6, 'emptyLinesDensity': 0.06666666666666667, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.30655391120507397}","def qft_circuit(qubits: Qubits) -> Circuit:
    
    

    N = len(qubits)
    circ = Circuit()
    for n0 in range(N):
        q0 = qubits[n0]
        circ += H(q0)
        for n1 in range(n0+1, N):
            q1 = qubits[n1]
            angle = pi / 2 ** (n1-n0)
            circ += CPHASE(angle, q1, q0)
    circ.extend(reversal_circuit(qubits))
    return circ"
"private void createOrUpdateColumnFamily(TableInfo tableInfo, KsDef ksDef) throws Exception
    {
        MetaDataHandler handler = new MetaDataHandler();

        if (containsCompositeKey(tableInfo))
        {
            validateCompoundKey(tableInfo);
            createOrUpdateUsingCQL3(tableInfo, ksDef);

            // After successful schema operation, perform index creation.
            createIndexUsingCql(tableInfo);
        }
        else if (containsCollectionColumns(tableInfo) || isCql3Enabled(tableInfo))
        {
            createOrUpdateUsingCQL3(tableInfo, ksDef);
            createIndexUsingCql(tableInfo);
        }
        else
        {

            CfDef cf_def = handler.getTableMetadata(tableInfo);
            try
            {
                cassandra_client.system_add_column_family(cf_def);
            }
            catch (InvalidRequestException irex)
            {
                updateExistingColumnFamily(tableInfo, ksDef, irex);
            }
        }
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 10.224137931034482, 'avgLineLength': 31.258064516129032, 'emptyLinesDensity': 0.0967741935483871, 'functionDefinitionDensity': 0.03225806451612903, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 2, 'whiteSpaceRatio': 0.3383383383383383}","private void createOrUpdateColumnFamily(TableInfo tableInfo, KsDef ksDef) throws Exception
    {
        MetaDataHandler handler = new MetaDataHandler();

        if (containsCompositeKey(tableInfo))
        {
            validateCompoundKey(tableInfo);
            createOrUpdateUsingCQL3(tableInfo, ksDef);

            
            createIndexUsingCql(tableInfo);
        }
        else if (containsCollectionColumns(tableInfo) || isCql3Enabled(tableInfo))
        {
            createOrUpdateUsingCQL3(tableInfo, ksDef);
            createIndexUsingCql(tableInfo);
        }
        else
        {

            CfDef cf_def = handler.getTableMetadata(tableInfo);
            try
            {
                cassandra_client.system_add_column_family(cf_def);
            }
            catch (InvalidRequestException irex)
            {
                updateExistingColumnFamily(tableInfo, ksDef, irex);
            }
        }
    }"
"@Override
    public boolean remove(long taskId, String owner, boolean removeIfEnded) throws Exception {
        StringBuilder delete = new StringBuilder(66)
                        .append(""DELETE FROM Task t WHERE t.ID=:i"");
        if (!removeIfEnded)
            delete.append("" AND t.STATES<"").append(TaskState.ENDED.bit);
        if (owner != null)
            delete.append("" AND t.OWNR=:o"");

        final boolean trace = TraceComponent.isAnyTracingEnabled();
        if (trace && tc.isEntryEnabled())
            Tr.entry(this, tc, ""remove"", taskId, owner, removeIfEnded, delete);

        EntityManager em = getPersistenceServiceUnit().createEntityManager();
        try {
            Query query = em.createQuery(delete.toString());
            query.setParameter(""i"", taskId);
            if (owner != null)
                query.setParameter(""o"", owner);

            boolean removed = query.executeUpdate() > 0;

            if (trace && tc.isEntryEnabled())
                Tr.exit(this, tc, ""remove"", removed);
            return removed;
        } finally {
            em.close();
        }
    }",java,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 5.933962264150943, 'avgLineLength': 37.48275862068966, 'emptyLinesDensity': 0.13793103448275862, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 3, 'whiteSpaceRatio': 0.31390134529147984}","@Override
    public boolean remove(long taskId, String owner, boolean removeIfEnded) throws Exception {
        StringBuilder delete = new StringBuilder(66)
                        .append(""DELETE FROM Task t WHERE t.ID=:i"");
        if (!removeIfEnded)
            delete.append("" AND t.STATES<"").append(TaskState.ENDED.bit);
        if (owner != null)
            delete.append("" AND t.OWNR=:o"");

        final boolean trace = TraceComponent.isAnyTracingEnabled();
        if (trace && tc.isEntryEnabled())
            Tr.entry(this, tc, ""remove"", taskId, owner, removeIfEnded, delete);

        EntityManager em = getPersistenceServiceUnit().createEntityManager();
        try {
            Query query = em.createQuery(delete.toString());
            query.setParameter(""i"", taskId);
            if (owner != null)
                query.setParameter(""o"", owner);

            boolean removed = query.executeUpdate() > 0;

            if (trace && tc.isEntryEnabled())
                Tr.exit(this, tc, ""remove"", removed);
            return removed;
        } finally {
            em.close();
        }
    }"
"@Override
    public void addChemModel(IChemModel chemModel) {
        if (chemModelCount + 1 >= chemModels.length) {
            growChemModelArray();
        }
        chemModels[chemModelCount] = chemModel;
        chemModelCount++;
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 9.1875, 'avgLineLength': 29.25, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.125, 'maintainabilityIndex': 14.119999999999994, 'maxDecisionTokens': 4, 'whiteSpaceRatio': 0.2946058091286307}","@Override
    public void addChemModel(IChemModel chemModel) {
        if (chemModelCount + 1 >= chemModels.length) {
            growChemModelArray();
        }
        chemModels[chemModelCount] = chemModel;
        chemModelCount++;
    }"
"def hist_path(self):
        """"""Absolute path of the HIST file. Empty string if file is not present.""""""
        # Lazy property to avoid multiple calls to has_abiext.
        try:
            return self._hist_path
        except AttributeError:
            path = self.outdir.has_abiext(""HIST"")
            if path: self._hist_path = path
            return path",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.214285714285714, 'avgLineLength': 39.44444444444444, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.1111111111111111, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.325068870523416}","def hist_path(self):
        
        
        try:
            return self._hist_path
        except AttributeError:
            path = self.outdir.has_abiext(""HIST"")
            if path: self._hist_path = path
            return path"
"public List<Association> getAssociationsForTarget(Class<? extends Model> targetModelClass) {
        List<Association> result = new ArrayList<>();
        for (Association association : associations) {
            if (association.getTargetClass().getName().equals(targetModelClass.getName())) {
                result.add(association);
            }
        }
        return result;
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 8.379310344827585, 'avgLineLength': 42.22222222222222, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.1111111111111111, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 3, 'whiteSpaceRatio': 0.26288659793814434}","public List<Association> getAssociationsForTarget(Class<? extends Model> targetModelClass) {
        List<Association> result = new ArrayList<>();
        for (Association association : associations) {
            if (association.getTargetClass().getName().equals(targetModelClass.getName())) {
                result.add(association);
            }
        }
        return result;
    }"
"def permute(self, qubits: Qubits) -> 'Gate':
        """"""Permute the order of the qubits""""""
        vec = self.vec.permute(qubits)
        return Gate(vec.tensor, qubits=vec.qubits)",python,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 4.708333333333333, 'avgLineLength': 44.25, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.22777777777777777}","def permute(self, qubits: Qubits) -> 'Gate':
        
        vec = self.vec.permute(qubits)
        return Gate(vec.tensor, qubits=vec.qubits)"
"def _find_files(root, includes, excludes, follow_symlinks):
    """"""List files inside a directory based on include and exclude rules.

    This is a more advanced version of `glob.glob`, that accepts multiple
    complex patterns.

    Args:
        root (str): base directory to list files from.
        includes (list[str]): inclusion patterns. Only files matching those
            patterns will be included in the result.
        excludes (list[str]): exclusion patterns. Files matching those
            patterns will be excluded from the result. Exclusions take
            precedence over inclusions.
        follow_symlinks (bool): If true, symlinks will be included in the
            resulting zip file

    Yields:
        str: a file name relative to the root.

    Note:
        Documentation for the patterns can be found at
        http://www.aviser.asia/formic/doc/index.html
    """"""

    root = os.path.abspath(root)
    file_set = formic.FileSet(
        directory=root, include=includes,
        exclude=excludes, symlinks=follow_symlinks,
    )

    for filename in file_set.qualified_files(absolute=False):
        yield filename",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.521428571428571, 'avgLineLength': 34.9375, 'emptyLinesDensity': 0.1875, 'functionDefinitionDensity': 0.03125, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.26022628372497825}","def _find_files(root, includes, excludes, follow_symlinks):
    

    root = os.path.abspath(root)
    file_set = formic.FileSet(
        directory=root, include=includes,
        exclude=excludes, symlinks=follow_symlinks,
    )

    for filename in file_set.qualified_files(absolute=False):
        yield filename"
"int NextChild(int i, vector<int> A) {
  if (A.size() == 0) {

 return 0;
  }
  int m1 = Query(A, i);
  if (m1 == 0) {

 return 0;
  }
  if (A.size() == 1) {

 return A.back();
  }
  int m2 = Query(A);
  if (m2 == m1) {

 return 0;
  }
  int j = NextChild(i, vector<int>(A.begin(), A.begin() + (A.size() / 2)));
  if (j == 0) {

 j = NextChild(i, vector<int>(A.begin() + (A.size() / 2), A.end()));
  }
  return j;
}",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 2.8405797101449277, 'avgLineLength': 14.961538461538462, 'emptyLinesDensity': 0.19230769230769232, 'functionDefinitionDensity': 15.961538461538462, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.27053140096618356}","int NextChild(int i, vector<int> A) {
  if (A.size() == 0) {

 return 0;
  }
  int m1 = Query(A, i);
  if (m1 == 0) {

 return 0;
  }
  if (A.size() == 1) {

 return A.back();
  }
  int m2 = Query(A);
  if (m2 == m1) {

 return 0;
  }
  int j = NextChild(i, vector<int>(A.begin(), A.begin() + (A.size() / 2)));
  if (j == 0) {

 j = NextChild(i, vector<int>(A.begin() + (A.size() / 2), A.end()));
  }
  return j;
}"
"public static void readIconicsCompoundButton(@NonNull Context ctx,
                                                 @Nullable AttributeSet attrs,
                                                 @NonNull CheckableIconBundle icon) {
        TypedArray a = ctx.obtainStyledAttributes(attrs, R.styleable.IconicsCompoundButton, 0, 0);

        //obtaining attributes for Unchecked icon state
        icon.mUncheckedIcon = getIconicsCompoundButtonUncheckedDrawable(ctx, a);

        //obtaining attributes for Checked icon state
        icon.mCheckedIcon = getIconicsCompoundButtonCheckedDrawable(ctx, a);

        a.recycle();
    }",java,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 8.404255319148936, 'avgLineLength': 47.38461538461539, 'emptyLinesDensity': 0.23076923076923078, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3089171974522293}","public static void readIconicsCompoundButton(@NonNull Context ctx,
                                                 @Nullable AttributeSet attrs,
                                                 @NonNull CheckableIconBundle icon) {
        TypedArray a = ctx.obtainStyledAttributes(attrs, R.styleable.IconicsCompoundButton, 0, 0);

        
        icon.mUncheckedIcon = getIconicsCompoundButtonUncheckedDrawable(ctx, a);

        
        icon.mCheckedIcon = getIconicsCompoundButtonCheckedDrawable(ctx, a);

        a.recycle();
    }"
"public boolean set(String value, Date expireAt) {
		if (value == null)
			return false;
		try {
			boolean result = getJedisCommands(groupName).set(key, value).equals(RESP_OK);
			if(result){
				result = setExpireAt(expireAt);
				//set
				Level1CacheSupport.getInstance().publishSyncEvent(key);
			}
			return result;
		} finally {
			getJedisProvider(groupName).release();
		}
	}",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 7.256410256410256, 'avgLineLength': 26.133333333333333, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.06666666666666667, 'maintainabilityIndex': 29.79333333333333, 'maxDecisionTokens': 2, 'whiteSpaceRatio': 0.17980295566502463}","public boolean set(String value, Date expireAt) {
		if (value == null)
			return false;
		try {
			boolean result = getJedisCommands(groupName).set(key, value).equals(RESP_OK);
			if(result){
				result = setExpireAt(expireAt);
				
				Level1CacheSupport.getInstance().publishSyncEvent(key);
			}
			return result;
		} finally {
			getJedisProvider(groupName).release();
		}
	}"
"def grid(self, dimensions=None, **kwargs):
        """"""
        Groups data by supplied dimension(s) laying the groups along
        the dimension(s) out in a GridSpace.

        Args:
        dimensions: Dimension/str or list
            Dimension or list of dimensions to group by

        Returns:
        grid: GridSpace
            GridSpace with supplied dimensions
        """"""
        return self.groupby(dimensions, container_type=GridSpace, **kwargs)",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.568627450980392, 'avgLineLength': 31.785714285714285, 'emptyLinesDensity': 0.14285714285714285, 'functionDefinitionDensity': 0.07142857142857142, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.31004366812227074}","def grid(self, dimensions=None, **kwargs):
        
        return self.groupby(dimensions, container_type=GridSpace, **kwargs)"
"void spush(int x) {

 if (slazy[x] != 0)


sapply(2 * x + 1, slazy[x]), sapply(2 * x + 2, slazy[x]), slazy[x] = 0;
  }",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 2.5652173913043477, 'avgLineLength': 16.0, 'emptyLinesDensity': 0.42857142857142855, 'functionDefinitionDensity': 17.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2457627118644068}","void spush(int x) {

 if (slazy[x] != 0)


sapply(2 * x + 1, slazy[x]), sapply(2 * x + 2, slazy[x]), slazy[x] = 0;
  }"
"def use_double_hash(password_hash=None):
    """"""Return a bool indicating whether a password should be hashed twice.""""""
    # Default to plaintext for backward compatibility with
    # SECURITY_PASSWORD_SINGLE_HASH = False
    single_hash = config_value('PASSWORD_SINGLE_HASH') or {'plaintext'}

    if password_hash is None:
        scheme = _security.password_hash
    else:
        scheme = _pwd_context.identify(password_hash)

    return not (single_hash is True or scheme in single_hash)",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 7.28, 'avgLineLength': 40.083333333333336, 'emptyLinesDensity': 0.16666666666666666, 'functionDefinitionDensity': 0.08333333333333333, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.19308943089430894}","def use_double_hash(password_hash=None):
    
    
    
    single_hash = config_value('PASSWORD_SINGLE_HASH') or {'plaintext'}

    if password_hash is None:
        scheme = _security.password_hash
    else:
        scheme = _pwd_context.identify(password_hash)

    return not (single_hash is True or scheme in single_hash)"
"def cql_query_with_prepare(query, statement_name, statement_arguments, callback_errors=None, contact_points=None,
                           port=None, cql_user=None, cql_pass=None, **kwargs):
    '''
    Run a query on a Cassandra cluster and return a dictionary.

    This function should not be used asynchronously for SELECTs -- it will not
    return anything and we don't currently have a mechanism for handling a future
    that will return results.

    :param query:          The query to execute.
    :type  query:          str
    :param statement_name: Name to assign the prepared statement in the __context__ dictionary
    :type  statement_name: str
    :param statement_arguments: Bind parameters for the SQL statement
    :type  statement_arguments: list[str]
    :param async:           Run this query in asynchronous mode
    :type  async:           bool
    :param callback_errors: Function to call after query runs if there is an error
    :type  callback_errors: Function callable
    :param contact_points: The Cassandra cluster addresses, can either be a string or a list of IPs.
    :type  contact_points: str | list[str]
    :param cql_user:       The Cassandra user if authentication is turned on.
    :type  cql_user:       str
    :param cql_pass:       The Cassandra user password if authentication is turned on.
    :type  cql_pass:       str
    :param port:           The Cassandra cluster port, defaults to None.
    :type  port:           int
    :param params:         The parameters for the query, optional.
    :type  params:         str
    :return:               A dictionary from the return values of the query
    :rtype:                list[dict]


    CLI Example:

    .. code-block:: bash

        # Insert data asynchronously
        salt this-node cassandra_cql.cql_query_with_prepare ""name_insert"" ""INSERT INTO USERS (first_name, last_name) VALUES (?, ?)"" \
            statement_arguments=['John','Doe'], asynchronous=True

        # Select data, should not be asynchronous because there is not currently a facility to return data from a future
        salt this-node cassandra_cql.cql_query_with_prepare ""name_select"" ""SELECT * FROM USERS WHERE first_name=?"" \
            statement_arguments=['John']
    '''
    # Backward-compatibility with Python 3.7: ""async"" is a reserved word
    asynchronous = kwargs.get('async', False)
    try:
        cluster, session = _connect(contact_points=contact_points, port=port,
                                    cql_user=cql_user, cql_pass=cql_pass)
    except CommandExecutionError:
        log.critical('Could not get Cassandra cluster session.')
        raise
    except BaseException as e:
        log.critical('Unexpected error while getting Cassandra cluster session: %s', e)
        raise

    if statement_name not in __context__['cassandra_cql_prepared']:
        try:
            bound_statement = session.prepare(query)
            __context__['cassandra_cql_prepared'][statement_name] = bound_statement
        except BaseException as e:
            log.critical('Unexpected error while preparing SQL statement: %s', e)
            raise
    else:
        bound_statement = __context__['cassandra_cql_prepared'][statement_name]

    session.row_factory = dict_factory
    ret = []

    try:
        if asynchronous:
            future_results = session.execute_async(bound_statement.bind(statement_arguments))
            # future_results.add_callbacks(_async_log_errors)
        else:
            results = session.execute(bound_statement.bind(statement_arguments))
    except BaseException as e:
        log.error('Failed to execute query: %s\n reason: %s', query, e)
        msg = ""ERROR: Cassandra query failed: {0} reason: {1}"".format(query, e)
        raise CommandExecutionError(msg)

    if not asynchronous and results:
        for result in results:
            values = {}
            for key, value in six.iteritems(result):
                # Salt won't return dictionaries with odd types like uuid.UUID
                if not isinstance(value, six.text_type):
                    # Must support Cassandra collection types.
                    # Namely, Cassandras set, list, and map collections.
                    if not isinstance(value, (set, list, dict)):
                        value = six.text_type(value)
                values[key] = value
            ret.append(values)

    # If this was a synchronous call, then we either have an empty list
    # because there was no return, or we have a return
    # If this was an asynchronous call we only return the empty list
    return ret",python,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 5.952475247524752, 'avgLineLength': 46.02040816326531, 'emptyLinesDensity': 0.12244897959183673, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2789233774690688}","def cql_query_with_prepare(query, statement_name, statement_arguments, callback_errors=None, contact_points=None,
                           port=None, cql_user=None, cql_pass=None, **kwargs):
    
    
    asynchronous = kwargs.get('async', False)
    try:
        cluster, session = _connect(contact_points=contact_points, port=port,
                                    cql_user=cql_user, cql_pass=cql_pass)
    except CommandExecutionError:
        log.critical('Could not get Cassandra cluster session.')
        raise
    except BaseException as e:
        log.critical('Unexpected error while getting Cassandra cluster session: %s', e)
        raise

    if statement_name not in __context__['cassandra_cql_prepared']:
        try:
            bound_statement = session.prepare(query)
            __context__['cassandra_cql_prepared'][statement_name] = bound_statement
        except BaseException as e:
            log.critical('Unexpected error while preparing SQL statement: %s', e)
            raise
    else:
        bound_statement = __context__['cassandra_cql_prepared'][statement_name]

    session.row_factory = dict_factory
    ret = []

    try:
        if asynchronous:
            future_results = session.execute_async(bound_statement.bind(statement_arguments))
            
        else:
            results = session.execute(bound_statement.bind(statement_arguments))
    except BaseException as e:
        log.error('Failed to execute query: %s\n reason: %s', query, e)
        msg = ""ERROR: Cassandra query failed: {0} reason: {1}"".format(query, e)
        raise CommandExecutionError(msg)

    if not asynchronous and results:
        for result in results:
            values = {}
            for key, value in six.iteritems(result):
                
                if not isinstance(value, six.text_type):
                    
                    
                    if not isinstance(value, (set, list, dict)):
                        value = six.text_type(value)
                values[key] = value
            ret.append(values)

    
    
    
    return ret"
"public static <T> EphemeralConst<T> of(
		final String name,
		final Supplier<T> supplier
	) {
		return new EphemeralConst<>(requireNonNull(name), supplier);
	}",java,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 6.105263157894737, 'avgLineLength': 25.833333333333332, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 32.333333333333314, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.15625}","public static <T> EphemeralConst<T> of(
		final String name,
		final Supplier<T> supplier
	) {
		return new EphemeralConst<>(requireNonNull(name), supplier);
	}"
"public Matrix3d set(FloatBuffer buffer) {
        MemUtil.INSTANCE.getf(this, buffer.position(), buffer);
        return this;
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 6.214285714285714, 'avgLineLength': 32.25, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.25, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.22727272727272727}","public Matrix3d set(FloatBuffer buffer) {
        MemUtil.INSTANCE.getf(this, buffer.position(), buffer);
        return this;
    }"
"def build(self, context, variant, build_path, install_path, install=False,
              build_type=BuildType.local):
        """"""Implement this method to perform the actual build.

        Args:
            context: A ResolvedContext object that the build process must be
                executed within.
            variant (`Variant`): The variant being built.
            build_path: Where to write temporary build files. May be relative
                to working_dir.
            install_path (str): The package repository path to install the
                package to, if installing. If None, defaults to
                `config.local_packages_path`.
            install: If True, install the build.
            build_type: A BuildType (i.e local or central).

        Returns:
            A dict containing the following information:
            - success: Bool indicating if the build was successful.
            - extra_files: List of created files of interest, not including
                build targets. A good example is the interpreted context file,
                usually named 'build.rxt.sh' or similar. These files should be
                located under build_path. Rez may install them for debugging
                purposes.
            - build_env_script: If this instance was created with write_build_scripts
                as True, then the build should generate a script which, when run
                by the user, places them in the build environment.
        """"""
        raise NotImplementedError",python,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 5.605882352941176, 'avgLineLength': 51.6551724137931, 'emptyLinesDensity': 0.06896551724137931, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.32830930537352554}","def build(self, context, variant, build_path, install_path, install=False,
              build_type=BuildType.local):
        
        raise NotImplementedError"
"@SuppressWarnings(""unchecked"")
	static void findByQuery(final EntityManager em, final String query)
    {
        Query q = em.createNamedQuery(query);

        logger.info(""[On Find All by Query]"");
        List<User> users = q.getResultList();

        if (users == null || users.isEmpty())
        {
            logger.info(""0 Users Returned"");
            return;
        }

        System.out.println(""#######################START##########################################"");
        logger.info(""\t\t Total number of users:"" + users.size());
        logger.info(""\t\t User's total tweets:"" + users.get(0).getTweets().size());
        printTweets(users);
        logger.info(""\n"");
        // logger.info(""First tweet:"" users.get(0).getTweets().);
        System.out.println(""#######################END############################################"");
        logger.info(""\n"");
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.906976744186046, 'avgLineLength': 38.56521739130435, 'emptyLinesDensity': 0.13043478260869565, 'functionDefinitionDensity': 0.043478260869565216, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 4, 'whiteSpaceRatio': 0.24972497249724973}","@SuppressWarnings(""unchecked"")
	static void findByQuery(final EntityManager em, final String query)
    {
        Query q = em.createNamedQuery(query);

        logger.info(""[On Find All by Query]"");
        List<User> users = q.getResultList();

        if (users == null || users.isEmpty())
        {
            logger.info(""0 Users Returned"");
            return;
        }

        System.out.println(""#######################START##########################################"");
        logger.info(""\t\t Total number of users:"" + users.size());
        logger.info(""\t\t User's total tweets:"" + users.get(0).getTweets().size());
        printTweets(users);
        logger.info(""\n"");
        
        System.out.println(""#######################END############################################"");
        logger.info(""\n"");
    }"
"int bat(int idx, long long int v) {
  if (v & (1ll << idx)) return 1;
  return 0;
}",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 2.9375, 'avgLineLength': 20.0, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 21.0, 'maintainabilityIndex': 43.779999999999994, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.26506024096385544}","int bat(int idx, long long int v) {
  if (v & (1ll << idx)) return 1;
  return 0;
}"
"def package_install(name, **kwargs):
    '''
    Install a ""package"" on the ssh server
    '''
    cmd = 'pkg_install ' + name
    if kwargs.get('version', False):
        cmd += ' ' + kwargs['version']

    # Send the command to execute
    out, err = DETAILS['server'].sendline(cmd)

    # ""scrape"" the output and return the right fields as a dict
    return parse(out)",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.808510638297872, 'avgLineLength': 27.615384615384617, 'emptyLinesDensity': 0.15384615384615385, 'functionDefinitionDensity': 0.07692307692307693, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2587601078167116}","def package_install(name, **kwargs):
    
    cmd = 'pkg_install ' + name
    if kwargs.get('version', False):
        cmd += ' ' + kwargs['version']

    
    out, err = DETAILS['server'].sendline(cmd)

    
    return parse(out)"
"def check(self, state, when):
        """"""
        Checks state `state` to see if the breakpoint should fire.

        :param state:   The state.
        :param when:    Whether the check is happening before or after the event.
        :return:        A boolean representing whether the checkpoint should fire.
        """"""
        ok = self.enabled and (when == self.when or self.when == BP_BOTH)
        if not ok:
            return ok
        l.debug(""... after enabled and when: %s"", ok)

        for a in [ _ for _ in self.kwargs if not _.endswith(""_unique"") ]:
            current_expr = getattr(state.inspect, a)
            needed = self.kwargs.get(a, None)

            l.debug(""... checking condition %s"", a)

            if current_expr is None and needed is None:
                l.debug(""...... both None, True"")
                c_ok = True
            elif current_expr is not None and needed is not None:
                if state.solver.solution(current_expr, needed):
                    l.debug(""...... is_solution!"")
                    c_ok = True
                else:
                    l.debug(""...... not solution..."")
                    c_ok = False

                if c_ok and self.kwargs.get(a+'_unique', True):
                    l.debug(""...... checking uniqueness"")
                    if not state.solver.unique(current_expr):
                        l.debug(""...... not unique"")
                        c_ok = False
            else:
                l.debug(""...... one None, False"")
                c_ok = False

            ok = ok and c_ok
            if not ok:
                return ok
            l.debug(""... after condition %s: %s"", a, ok)

        ok = ok and (self.condition is None or self.condition(state))
        l.debug(""... after condition func: %s"", ok)
        return ok",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.264423076923077, 'avgLineLength': 37.808510638297875, 'emptyLinesDensity': 0.14893617021276595, 'functionDefinitionDensity': 0.02127659574468085, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3987931980252331}","def check(self, state, when):
        
        ok = self.enabled and (when == self.when or self.when == BP_BOTH)
        if not ok:
            return ok
        l.debug(""... after enabled and when: %s"", ok)

        for a in [ _ for _ in self.kwargs if not _.endswith(""_unique"") ]:
            current_expr = getattr(state.inspect, a)
            needed = self.kwargs.get(a, None)

            l.debug(""... checking condition %s"", a)

            if current_expr is None and needed is None:
                l.debug(""...... both None, True"")
                c_ok = True
            elif current_expr is not None and needed is not None:
                if state.solver.solution(current_expr, needed):
                    l.debug(""...... is_solution!"")
                    c_ok = True
                else:
                    l.debug(""...... not solution..."")
                    c_ok = False

                if c_ok and self.kwargs.get(a+'_unique', True):
                    l.debug(""...... checking uniqueness"")
                    if not state.solver.unique(current_expr):
                        l.debug(""...... not unique"")
                        c_ok = False
            else:
                l.debug(""...... one None, False"")
                c_ok = False

            ok = ok and c_ok
            if not ok:
                return ok
            l.debug(""... after condition %s: %s"", a, ok)

        ok = ok and (self.condition is None or self.condition(state))
        l.debug(""... after condition func: %s"", ok)
        return ok"
"public MinMax<C> combine(final MinMax<C> other) {
		_min = min(_comparator, _min, other._min);
		_max = max(_comparator, _max, other._max);
		_count += other._count;

		return this;
	}",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.04, 'avgLineLength': 25.428571428571427, 'emptyLinesDensity': 0.14285714285714285, 'functionDefinitionDensity': 0.14285714285714285, 'maintainabilityIndex': 11.533333333333331, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.16847826086956522}","public MinMax<C> combine(final MinMax<C> other) {
		_min = min(_comparator, _min, other._min);
		_max = max(_comparator, _max, other._max);
		_count += other._count;

		return this;
	}"
"def fix_one_step_and_explain(text):
    """"""
    Performs a single step of re-decoding text that's been decoded incorrectly.

    Returns the decoded text, plus a ""plan"" for how to reproduce what it did.
    """"""
    if isinstance(text, bytes):
        raise UnicodeError(BYTES_ERROR_TEXT)
    if len(text) == 0:
        return text, []

    # The first plan is to return ASCII text unchanged.
    if possible_encoding(text, 'ascii'):
        return text, []

    # As we go through the next step, remember the possible encodings
    # that we encounter but don't successfully fix yet. We may need them
    # later.
    possible_1byte_encodings = []

    # Suppose the text was supposed to be UTF-8, but it was decoded using
    # a single-byte encoding instead. When these cases can be fixed, they
    # are usually the correct thing to do, so try them next.
    for encoding in CHARMAP_ENCODINGS:
        if possible_encoding(text, encoding):
            encoded_bytes = text.encode(encoding)
            encode_step = ('encode', encoding, ENCODING_COSTS.get(encoding, 0))
            transcode_steps = []

            # Now, find out if it's UTF-8 (or close enough). Otherwise,
            # remember the encoding for later.
            try:
                decoding = 'utf-8'
                # Check encoded_bytes for sequences that would be UTF-8,
                # except they have b' ' where b'\xa0' would belong.
                if ALTERED_UTF8_RE.search(encoded_bytes):
                    encoded_bytes = restore_byte_a0(encoded_bytes)
                    cost = encoded_bytes.count(0xa0) * 2
                    transcode_steps.append(('transcode', 'restore_byte_a0', cost))

                # Check for the byte 0x1a, which indicates where one of our
                # 'sloppy' codecs found a replacement character.
                if encoding.startswith('sloppy') and 0x1a in encoded_bytes:
                    encoded_bytes = replace_lossy_sequences(encoded_bytes)
                    transcode_steps.append(('transcode', 'replace_lossy_sequences', 0))

                if 0xed in encoded_bytes or 0xc0 in encoded_bytes:
                    decoding = 'utf-8-variants'

                decode_step = ('decode', decoding, 0)
                steps = [encode_step] + transcode_steps + [decode_step]
                fixed = encoded_bytes.decode(decoding)
                return fixed, steps

            except UnicodeDecodeError:
                possible_1byte_encodings.append(encoding)

    # Look for a-hat-euro sequences that remain, and fix them in isolation.
    if PARTIAL_UTF8_PUNCT_RE.search(text):
        steps = [('transcode', 'fix_partial_utf8_punct_in_1252', 1)]
        fixed = fix_partial_utf8_punct_in_1252(text)
        return fixed, steps

    # The next most likely case is that this is Latin-1 that was intended to
    # be read as Windows-1252, because those two encodings in particular are
    # easily confused.
    if 'latin-1' in possible_1byte_encodings:
        if 'windows-1252' in possible_1byte_encodings:
            # This text is in the intersection of Latin-1 and
            # Windows-1252, so it's probably legit.
            return text, []
        else:
            # Otherwise, it means we have characters that are in Latin-1 but
            # not in Windows-1252. Those are C1 control characters. Nobody
            # wants those. Assume they were meant to be Windows-1252. Don't
            # use the sloppy codec, because bad Windows-1252 characters are
            # a bad sign.
            encoded = text.encode('latin-1')
            try:
                fixed = encoded.decode('windows-1252')
                steps = []
                if fixed != text:
                    steps = [('encode', 'latin-1', 0),
                             ('decode', 'windows-1252', 1)]
                return fixed, steps
            except UnicodeDecodeError:
                # This text contained characters that don't even make sense
                # if you assume they were supposed to be Windows-1252. In
                # that case, let's not assume anything.
                pass

    # The cases that remain are mixups between two different single-byte
    # encodings, and not the common case of Latin-1 vs. Windows-1252.
    #
    # These cases may be unsolvable without adding false positives, though
    # I have vague ideas about how to optionally address them in the future.

    # Return the text unchanged; the plan is empty.
    return text, []",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.3968565815324165, 'avgLineLength': 44.474747474747474, 'emptyLinesDensity': 0.13131313131313133, 'functionDefinitionDensity': 0.010101010101010102, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3170406576316374}","def fix_one_step_and_explain(text):
    
    if isinstance(text, bytes):
        raise UnicodeError(BYTES_ERROR_TEXT)
    if len(text) == 0:
        return text, []

    
    if possible_encoding(text, 'ascii'):
        return text, []

    
    
    
    possible_1byte_encodings = []

    
    
    
    for encoding in CHARMAP_ENCODINGS:
        if possible_encoding(text, encoding):
            encoded_bytes = text.encode(encoding)
            encode_step = ('encode', encoding, ENCODING_COSTS.get(encoding, 0))
            transcode_steps = []

            
            
            try:
                decoding = 'utf-8'
                
                
                if ALTERED_UTF8_RE.search(encoded_bytes):
                    encoded_bytes = restore_byte_a0(encoded_bytes)
                    cost = encoded_bytes.count(0xa0) * 2
                    transcode_steps.append(('transcode', 'restore_byte_a0', cost))

                
                
                if encoding.startswith('sloppy') and 0x1a in encoded_bytes:
                    encoded_bytes = replace_lossy_sequences(encoded_bytes)
                    transcode_steps.append(('transcode', 'replace_lossy_sequences', 0))

                if 0xed in encoded_bytes or 0xc0 in encoded_bytes:
                    decoding = 'utf-8-variants'

                decode_step = ('decode', decoding, 0)
                steps = [encode_step] + transcode_steps + [decode_step]
                fixed = encoded_bytes.decode(decoding)
                return fixed, steps

            except UnicodeDecodeError:
                possible_1byte_encodings.append(encoding)

    
    if PARTIAL_UTF8_PUNCT_RE.search(text):
        steps = [('transcode', 'fix_partial_utf8_punct_in_1252', 1)]
        fixed = fix_partial_utf8_punct_in_1252(text)
        return fixed, steps

    
    
    
    if 'latin-1' in possible_1byte_encodings:
        if 'windows-1252' in possible_1byte_encodings:
            
            
            return text, []
        else:
            
            
            
            
            
            encoded = text.encode('latin-1')
            try:
                fixed = encoded.decode('windows-1252')
                steps = []
                if fixed != text:
                    steps = [('encode', 'latin-1', 0),
                             ('decode', 'windows-1252', 1)]
                return fixed, steps
            except UnicodeDecodeError:
                
                
                
                pass

    
    
    
    
    

    
    return text, []"
"def ucm(self, data: ['SASdata', str] = None,
            autoreg: str = None,
            blockseason: str = None,
            by: str = None,
            cycle: str = None,
            deplag: str = None,
            estimate: [str, bool] = None,
            forecast: str = None,
            id: str = None,
            irregular: [str, bool] = None,
            level: [str, bool] = None,
            model: str = None,
            nloptions: str = None,
            out: [str, 'SASdata'] = None,
            outlier: str = None,
            performance: str = None,
            randomreg: str = None,
            season: str = None,
            slope: [str, bool] = None,
            splinereg: str = None,
            splineseason: str = None,
            procopts: str = None,
            stmtpassthrough: str = None,
            **kwargs: dict) -> 'SASresults':
        """"""
        Python method to call the UCM procedure

        Documentation link:
        http://support.sas.com/documentation/cdl//en/etsug/68148/HTML/default/viewer.htm#etsug_ucm_syntax.htm

        :param data: SASdata object or string. This parameter is required.
        :parm autoreg: The autoreg variable can only be a string type.
        :parm blockseason: The blockseason variable can only be a string type.
        :parm by: The by variable can only be a string type.
        :parm cycle: The cycle variable can only be a string type.
        :parm deplag: The deplag variable can only be a string type.
        :parm estimate: The estimate variable can be a string or boolean type.
        :parm forecast: The forecast variable can only be a string type.
        :parm id: The id variable can only be a string type.
        :parm irregular: The irregular variable can be a string or boolean type.
        :parm level: The level variable can be a string or boolean type.
        :parm model: The model variable can only be a string type.
        :parm nloptions: The nloptions variable can only be a string type.
        :parm out: The out variable can be a string or SASdata type.
        :parm outlier: The outlier variable can only be a string type.
        :parm performance: The performance variable can only be a string type.
        :parm randomreg: The randomreg variable can only be a string type.
        :parm season: The season variable can only be a string type.
        :parm slope: The slope variable can be a string or boolean type.
        :parm splinereg: The splinereg variable can only be a string type.
        :parm splineseason: The splineseason variable can only be a string type.
        :parm procopts: The procopts variable is a generic option available for advanced use. It can only be a string type.
        :parm stmtpassthrough: The stmtpassthrough variable is a generic option available for advanced use. It can only be a string type.
        :return: SAS Result Object
        """"""",python,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 4.677083333333333, 'avgLineLength': 51.74545454545454, 'emptyLinesDensity': 0.03636363636363636, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3117241379310345}","def ucm(self, data: ['SASdata', str] = None,
            autoreg: str = None,
            blockseason: str = None,
            by: str = None,
            cycle: str = None,
            deplag: str = None,
            estimate: [str, bool] = None,
            forecast: str = None,
            id: str = None,
            irregular: [str, bool] = None,
            level: [str, bool] = None,
            model: str = None,
            nloptions: str = None,
            out: [str, 'SASdata'] = None,
            outlier: str = None,
            performance: str = None,
            randomreg: str = None,
            season: str = None,
            slope: [str, bool] = None,
            splinereg: str = None,
            splineseason: str = None,
            procopts: str = None,
            stmtpassthrough: str = None,
            **kwargs: dict) -> 'SASresults':
        "
"def pin(self, disable_notification: bool = None) -> ""Message"":
        """"""Bound method *pin* of :obj:`Message <pyrogram.Message>`.

        Use as a shortcut for:

        .. code-block:: python

            client.pin_chat_message(
                chat_id=message.chat.id,
                message_id=message_id
            )

        Example:
            .. code-block:: python

                message.pin()

        Args:
            disable_notification (``bool``):
                Pass True, if it is not necessary to send a notification to all chat members about the new pinned
                message. Notifications are always disabled in channels.

        Returns:
            True on success.

        Raises:
            :class:`RPCError <pyrogram.RPCError>`
        """"""
        return self._client.pin_chat_message(
            chat_id=self.chat.id,
            message_id=self.message_id,
            disable_notification=disable_notification
        )",python,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 6.068181818181818, 'avgLineLength': 28.272727272727273, 'emptyLinesDensity': 0.24242424242424243, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3616580310880829}","def pin(self, disable_notification: bool = None) -> ""Message"":
        
        return self._client.pin_chat_message(
            chat_id=self.chat.id,
            message_id=self.message_id,
            disable_notification=disable_notification
        )"
"def create_hook(self, name, config, events=github.GithubObject.NotSet, active=github.GithubObject.NotSet):
        """"""
        :calls: `POST /orgs/:owner/hooks <http://developer.github.com/v3/orgs/hooks>`_
        :param name: string
        :param config: dict
        :param events: list of string
        :param active: bool
        :rtype: :class:`github.Hook.Hook`
        """"""
        assert isinstance(name, (str, unicode)), name
        assert isinstance(config, dict), config
        assert events is github.GithubObject.NotSet or all(isinstance(element, (str, unicode)) for element in events), events
        assert active is github.GithubObject.NotSet or isinstance(active, bool), active
        post_parameters = {
            ""name"": name,
            ""config"": config,
        }
        if events is not github.GithubObject.NotSet:
            post_parameters[""events""] = events
        if active is not github.GithubObject.NotSet:
            post_parameters[""active""] = active
        headers, data = self._requester.requestJsonAndCheck(
            ""POST"",
            self.url + ""/hooks"",
            input=post_parameters
        )
        return github.Hook.Hook(self._requester, headers, data, completed=True)",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.876923076923077, 'avgLineLength': 44.55555555555556, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.037037037037037035, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2701383238405207}","def create_hook(self, name, config, events=github.GithubObject.NotSet, active=github.GithubObject.NotSet):
        
        assert isinstance(name, (str, unicode)), name
        assert isinstance(config, dict), config
        assert events is github.GithubObject.NotSet or all(isinstance(element, (str, unicode)) for element in events), events
        assert active is github.GithubObject.NotSet or isinstance(active, bool), active
        post_parameters = {
            ""name"": name,
            ""config"": config,
        }
        if events is not github.GithubObject.NotSet:
            post_parameters[""events""] = events
        if active is not github.GithubObject.NotSet:
            post_parameters[""active""] = active
        headers, data = self._requester.requestJsonAndCheck(
            ""POST"",
            self.url + ""/hooks"",
            input=post_parameters
        )
        return github.Hook.Hook(self._requester, headers, data, completed=True)"
"void ff2(int x) {
  if (o[ff(p0, x)]) f[x]++;
  for (int i = h1[x]; i; i = e[i].ne) {

 int y = e[i].ad;

 if (de[y] == de[x] + 1) {


if (ff(p0, x) == ff(p0, y)) o[y] |= o[x];


f[y] = f[x], ff2(y);

 }
  }
}",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 1.5918367346938775, 'avgLineLength': 11.352941176470589, 'emptyLinesDensity': 0.4117647058823529, 'functionDefinitionDensity': 12.352941176470589, 'maintainabilityIndex': 14.020000000000003, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.28708133971291866}","void ff2(int x) {
  if (o[ff(p0, x)]) f[x]++;
  for (int i = h1[x]; i; i = e[i].ne) {

 int y = e[i].ad;

 if (de[y] == de[x] + 1) {


if (ff(p0, x) == ff(p0, y)) o[y] |= o[x];


f[y] = f[x], ff2(y);

 }
  }
}"
"void insert_vec(int t, int x) {
  for (int i = LOGN - 1; i >= 0; i--) basis[t][i] = basis[t - 1][i];
  for (int i = LOGN - 1; i >= 0; i--) {

 if ((x >> i) & 1) {


if (!basis[t][i]) {


  basis[t][i] = x;


  return;


} else {


  x ^= basis[t][i];


}

 }
  }
}",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 2.276595744680851, 'avgLineLength': 8.814814814814815, 'emptyLinesDensity': 0.5185185185185185, 'functionDefinitionDensity': 9.814814814814815, 'maintainabilityIndex': 4.450000000000003, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.32196969696969696}","void insert_vec(int t, int x) {
  for (int i = LOGN - 1; i >= 0; i--) basis[t][i] = basis[t - 1][i];
  for (int i = LOGN - 1; i >= 0; i--) {

 if ((x >> i) & 1) {


if (!basis[t][i]) {


  basis[t][i] = x;


  return;


} else {


  x ^= basis[t][i];


}

 }
  }
}"
"private boolean matches(Type type, IAtom atom, int stereo) {
        switch (type) {
            // predicates
            case TRUE:
                return true;
            case FALSE:
                return false;
            case IS_AROMATIC:
                return atom.isAromatic();
            case IS_ALIPHATIC:
                return !atom.isAromatic();
            case IS_IN_RING:
                return atom.isInRing();
            case IS_IN_CHAIN:
                return !atom.isInRing();
            case IS_HETERO:
                return !eq(atom.getAtomicNumber(), 6) &&
                       !eq(atom.getAtomicNumber(), 1);
            case HAS_IMPLICIT_HYDROGEN:
                return atom.getImplicitHydrogenCount() != null &&
                       atom.getImplicitHydrogenCount() > 0;
            case HAS_ISOTOPE:
                return atom.getMassNumber() != null;
            case HAS_UNSPEC_ISOTOPE:
                return atom.getMassNumber() == null;
            case UNSATURATED:
                for (IBond bond : atom.bonds())
                    if (bond.getOrder() == IBond.Order.DOUBLE)
                        return true;
                return false;
            // value primitives
            case ELEMENT:
                return eq(atom.getAtomicNumber(), value);
            case ALIPHATIC_ELEMENT:
                return !atom.isAromatic() &&
                       eq(atom.getAtomicNumber(), value);
            case AROMATIC_ELEMENT:
                return atom.isAromatic() &&
                       eq(atom.getAtomicNumber(), value);
            case IMPL_H_COUNT:
                return eq(atom.getImplicitHydrogenCount(), value);
            case TOTAL_H_COUNT:
                if (atom.getImplicitHydrogenCount() != null
                    && atom.getImplicitHydrogenCount() > value)
                    return false;
                return getTotalHCount(atom) == value;
            case DEGREE:
                return atom.getBondCount() == value;
            case HEAVY_DEGREE: // XXX: CDK quirk
                return atom.getBondCount() - (getTotalHCount(atom) - atom.getImplicitHydrogenCount()) == value;
            case TOTAL_DEGREE:
                int x = atom.getBondCount() + unbox(atom.getImplicitHydrogenCount());
                return x == value;
            case VALENCE:
                int v = unbox(atom.getImplicitHydrogenCount());
                if (v > value)
                    return false;
                for (IBond bond : atom.bonds()) {
                    if (bond.getOrder() != null)
                        v += bond.getOrder().numeric();
                }
                return v == value;
            case ISOTOPE:
                return eq(atom.getMassNumber(), value);
            case FORMAL_CHARGE:
                return eq(atom.getFormalCharge(), value);
            case RING_BOND_COUNT:
                if (!atom.isInRing() || atom.getBondCount() < value)
                    return false;
                int rbonds = 0;
                for (IBond bond : atom.bonds())
                    rbonds += bond.isInRing() ? 1 : 0;
                return rbonds == value;
            case RING_COUNT:
                return atom.isInRing() && getRingCount(atom) == value;
            case RING_SMALLEST:
                return atom.isInRing() && isInSmallRingSize(atom, value);
            case RING_SIZE:
                return atom.isInRing() && isInRingSize(atom, value);
            case HETERO_SUBSTITUENT_COUNT:
                if (atom.getBondCount() < value)
                    return false;
                int q = 0;
                for (IBond bond : atom.bonds())
                    q += matches(Type.IS_HETERO, bond.getOther(atom), stereo) ? 1 : 0;
                return q == value;
            case INSATURATION:
                int db = 0;
                for (IBond bond : atom.bonds())
                    if (bond.getOrder() == IBond.Order.DOUBLE)
                        db++;
                return db == value;
            case HYBRIDISATION_NUMBER:
                IAtomType.Hybridization hyb = atom.getHybridization();
                if (hyb == null)
                    return false;
                switch (value) {
                    case 1:
                        return hyb == IAtomType.Hybridization.SP1;
                    case 2:
                        return hyb == IAtomType.Hybridization.SP2;
                    case 3:
                        return hyb == IAtomType.Hybridization.SP3;
                    case 4:
                        return hyb == IAtomType.Hybridization.SP3D1;
                    case 5:
                        return hyb == IAtomType.Hybridization.SP3D2;
                    case 6:
                        return hyb == IAtomType.Hybridization.SP3D3;
                    case 7:
                        return hyb == IAtomType.Hybridization.SP3D4;
                    case 8:
                        return hyb == IAtomType.Hybridization.SP3D5;
                    default:
                        return false;
                }
            case PERIODIC_GROUP:
                return atom.getAtomicNumber() != null &&
                       Elements.ofNumber(atom.getAtomicNumber()).group() == value;
            case STEREOCHEMISTRY:
                return stereo == UNKNOWN_STEREO || stereo == value;
            case REACTION_ROLE:
                ReactionRole role = atom.getProperty(CDKConstants.REACTION_ROLE);
                return role != null && role.ordinal() == value;
            case AND:
                return left.matches(left.type, atom, stereo) &&
                       right.matches(right.type, atom, stereo);
            case OR:
                return left.matches(left.type, atom, stereo) ||
                       right.matches(right.type, atom, stereo);
            case NOT:
                return !left.matches(left.type, atom, stereo) ||
                       // XXX: ugly but needed, when matching stereo
                       (stereo == UNKNOWN_STEREO &&
                        (left.type == STEREOCHEMISTRY ||
                         left.type == OR && left.left.type == STEREOCHEMISTRY));
            case RECURSIVE:
                if (ptrn == null)
                    ptrn = DfPattern.findSubstructure(query);
                return ptrn.matchesRoot(atom);
            default:
                throw new IllegalArgumentException(""Cannot match AtomExpr, type="" + type);
        }
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 6.17741935483871, 'avgLineLength': 44.041666666666664, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.006944444444444444, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 4, 'whiteSpaceRatio': 0.43731688511950656}","private boolean matches(Type type, IAtom atom, int stereo) {
        switch (type) {
            
            case TRUE:
                return true;
            case FALSE:
                return false;
            case IS_AROMATIC:
                return atom.isAromatic();
            case IS_ALIPHATIC:
                return !atom.isAromatic();
            case IS_IN_RING:
                return atom.isInRing();
            case IS_IN_CHAIN:
                return !atom.isInRing();
            case IS_HETERO:
                return !eq(atom.getAtomicNumber(), 6) &&
                       !eq(atom.getAtomicNumber(), 1);
            case HAS_IMPLICIT_HYDROGEN:
                return atom.getImplicitHydrogenCount() != null &&
                       atom.getImplicitHydrogenCount() > 0;
            case HAS_ISOTOPE:
                return atom.getMassNumber() != null;
            case HAS_UNSPEC_ISOTOPE:
                return atom.getMassNumber() == null;
            case UNSATURATED:
                for (IBond bond : atom.bonds())
                    if (bond.getOrder() == IBond.Order.DOUBLE)
                        return true;
                return false;
            
            case ELEMENT:
                return eq(atom.getAtomicNumber(), value);
            case ALIPHATIC_ELEMENT:
                return !atom.isAromatic() &&
                       eq(atom.getAtomicNumber(), value);
            case AROMATIC_ELEMENT:
                return atom.isAromatic() &&
                       eq(atom.getAtomicNumber(), value);
            case IMPL_H_COUNT:
                return eq(atom.getImplicitHydrogenCount(), value);
            case TOTAL_H_COUNT:
                if (atom.getImplicitHydrogenCount() != null
                    && atom.getImplicitHydrogenCount() > value)
                    return false;
                return getTotalHCount(atom) == value;
            case DEGREE:
                return atom.getBondCount() == value;
            case HEAVY_DEGREE: 
                return atom.getBondCount() - (getTotalHCount(atom) - atom.getImplicitHydrogenCount()) == value;
            case TOTAL_DEGREE:
                int x = atom.getBondCount() + unbox(atom.getImplicitHydrogenCount());
                return x == value;
            case VALENCE:
                int v = unbox(atom.getImplicitHydrogenCount());
                if (v > value)
                    return false;
                for (IBond bond : atom.bonds()) {
                    if (bond.getOrder() != null)
                        v += bond.getOrder().numeric();
                }
                return v == value;
            case ISOTOPE:
                return eq(atom.getMassNumber(), value);
            case FORMAL_CHARGE:
                return eq(atom.getFormalCharge(), value);
            case RING_BOND_COUNT:
                if (!atom.isInRing() || atom.getBondCount() < value)
                    return false;
                int rbonds = 0;
                for (IBond bond : atom.bonds())
                    rbonds += bond.isInRing() ? 1 : 0;
                return rbonds == value;
            case RING_COUNT:
                return atom.isInRing() && getRingCount(atom) == value;
            case RING_SMALLEST:
                return atom.isInRing() && isInSmallRingSize(atom, value);
            case RING_SIZE:
                return atom.isInRing() && isInRingSize(atom, value);
            case HETERO_SUBSTITUENT_COUNT:
                if (atom.getBondCount() < value)
                    return false;
                int q = 0;
                for (IBond bond : atom.bonds())
                    q += matches(Type.IS_HETERO, bond.getOther(atom), stereo) ? 1 : 0;
                return q == value;
            case INSATURATION:
                int db = 0;
                for (IBond bond : atom.bonds())
                    if (bond.getOrder() == IBond.Order.DOUBLE)
                        db++;
                return db == value;
            case HYBRIDISATION_NUMBER:
                IAtomType.Hybridization hyb = atom.getHybridization();
                if (hyb == null)
                    return false;
                switch (value) {
                    case 1:
                        return hyb == IAtomType.Hybridization.SP1;
                    case 2:
                        return hyb == IAtomType.Hybridization.SP2;
                    case 3:
                        return hyb == IAtomType.Hybridization.SP3;
                    case 4:
                        return hyb == IAtomType.Hybridization.SP3D1;
                    case 5:
                        return hyb == IAtomType.Hybridization.SP3D2;
                    case 6:
                        return hyb == IAtomType.Hybridization.SP3D3;
                    case 7:
                        return hyb == IAtomType.Hybridization.SP3D4;
                    case 8:
                        return hyb == IAtomType.Hybridization.SP3D5;
                    default:
                        return false;
                }
            case PERIODIC_GROUP:
                return atom.getAtomicNumber() != null &&
                       Elements.ofNumber(atom.getAtomicNumber()).group() == value;
            case STEREOCHEMISTRY:
                return stereo == UNKNOWN_STEREO || stereo == value;
            case REACTION_ROLE:
                ReactionRole role = atom.getProperty(CDKConstants.REACTION_ROLE);
                return role != null && role.ordinal() == value;
            case AND:
                return left.matches(left.type, atom, stereo) &&
                       right.matches(right.type, atom, stereo);
            case OR:
                return left.matches(left.type, atom, stereo) ||
                       right.matches(right.type, atom, stereo);
            case NOT:
                return !left.matches(left.type, atom, stereo) ||
                       
                       (stereo == UNKNOWN_STEREO &&
                        (left.type == STEREOCHEMISTRY ||
                         left.type == OR && left.left.type == STEREOCHEMISTRY));
            case RECURSIVE:
                if (ptrn == null)
                    ptrn = DfPattern.findSubstructure(query);
                return ptrn.matchesRoot(atom);
            default:
                throw new IllegalArgumentException(""Cannot match AtomExpr, type="" + type);
        }
    }"
"def require_int(self, key: str) -> int:
        """"""
        Returns a configuration value, as an int, by its given key.  If it doesn't exist, or the
        configuration value is not a legal int, an error is thrown.

        :param str key: The requested configuration key.
        :return: The configuration key's value.
        :rtype: int
        :raises ConfigMissingError: The configuration value did not exist.
        :raises ConfigTypeError: The configuration value existed but couldn't be coerced to int.
        """"""
        v = self.get_int(key)
        if v is None:
            raise ConfigMissingError(self.full_key(key))
        return v",python,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 4.837209302325581, 'avgLineLength': 42.53333333333333, 'emptyLinesDensity': 0.06666666666666667, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.29141104294478526}","def require_int(self, key: str) -> int:
        
        v = self.get_int(key)
        if v is None:
            raise ConfigMissingError(self.full_key(key))
        return v"
"void printg(long long x, long long p = -1) {
  for (long long to : g[x]) {

 cout << x + 1 <<
  << to + 1 << endl;

 printg(to, x);
  }
}",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 2.75, 'avgLineLength': 14.333333333333334, 'emptyLinesDensity': 0.2222222222222222, 'functionDefinitionDensity': 15.333333333333334, 'maintainabilityIndex': 37.48857142857141, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.30656934306569344}","void printg(long long x, long long p = -1) {
  for (long long to : g[x]) {

 cout << x + 1 <<
  << to + 1 << endl;

 printg(to, x);
  }
}"
"def destination(self, point, bearing, distance=None):
        """"""
        TODO docs.
        """"""
        point = Point(point)
        lat1 = point.latitude
        lon1 = point.longitude
        azi1 = bearing

        if distance is None:
            distance = self
        if isinstance(distance, Distance):
            distance = distance.kilometers

        if not (isinstance(self.geod, Geodesic) and
                self.geod.a == self.ELLIPSOID[0] and
                self.geod.f == self.ELLIPSOID[2]):
            self.geod = Geodesic(self.ELLIPSOID[0], self.ELLIPSOID[2])

        r = self.geod.Direct(lat1, lon1, azi1, distance,
                             Geodesic.LATITUDE | Geodesic.LONGITUDE)

        return Point(r['lat2'], r['lon2'])",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.1125, 'avgLineLength': 31.73913043478261, 'emptyLinesDensity': 0.17391304347826086, 'functionDefinitionDensity': 0.043478260869565216, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.34308510638297873}","def destination(self, point, bearing, distance=None):
        
        point = Point(point)
        lat1 = point.latitude
        lon1 = point.longitude
        azi1 = bearing

        if distance is None:
            distance = self
        if isinstance(distance, Distance):
            distance = distance.kilometers

        if not (isinstance(self.geod, Geodesic) and
                self.geod.a == self.ELLIPSOID[0] and
                self.geod.f == self.ELLIPSOID[2]):
            self.geod = Geodesic(self.ELLIPSOID[0], self.ELLIPSOID[2])

        r = self.geod.Direct(lat1, lon1, azi1, distance,
                             Geodesic.LATITUDE | Geodesic.LONGITUDE)

        return Point(r['lat2'], r['lon2'])"
"def prt_keys(self, prt, pre):
        """"""Print the alias for a relationship and its alias.""""""
        prt.write('{PRE}Relationship to parent: {ABC}\n'.format(
            PRE=pre, ABC=''.join(self.rel2chr.values())))
        for rel, alias in self.rel2chr.items():
            prt.write('{PRE}    {A} {DESC}\n'.format(PRE=pre, A=alias, DESC=rel))
        prt.write('\n{PRE}Relationship to child: {ABC}\n'.format(
            PRE=pre, ABC=''.join(self.rev2chr.values())))
        for rel, alias in self.rev2chr.items():
            prt.write('{PRE}    {A} {DESC}\n'.format(PRE=pre, A=alias, DESC=rel))",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 3.9655172413793105, 'avgLineLength': 59.1, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.1, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.23}","def prt_keys(self, prt, pre):
        
        prt.write('{PRE}Relationship to parent: {ABC}\n'.format(
            PRE=pre, ABC=''.join(self.rel2chr.values())))
        for rel, alias in self.rel2chr.items():
            prt.write('{PRE}    {A} {DESC}\n'.format(PRE=pre, A=alias, DESC=rel))
        prt.write('\n{PRE}Relationship to child: {ABC}\n'.format(
            PRE=pre, ABC=''.join(self.rev2chr.values())))
        for rel, alias in self.rev2chr.items():
            prt.write('{PRE}    {A} {DESC}\n'.format(PRE=pre, A=alias, DESC=rel))"
"static int computeLgK(final double threshold, final double rse) {
    final double v = Math.ceil(1.0 / (threshold * rse * rse));
    final int lgK = (int) Math.ceil(Math.log(v) / Math.log(2));
    if (lgK > MAX_LG_NOM_LONGS) {
      throw new SketchesArgumentException(""Requested Sketch (LgK = "" + lgK + "" &gt; 2^26), ""
          + ""either increase the threshold, the rse or both."");
    }
    return lgK;
  }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.722222222222222, 'avgLineLength': 44.55555555555556, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.1111111111111111, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 2, 'whiteSpaceRatio': 0.2371638141809291}","static int computeLgK(final double threshold, final double rse) {
    final double v = Math.ceil(1.0 / (threshold * rse * rse));
    final int lgK = (int) Math.ceil(Math.log(v) / Math.log(2));
    if (lgK > MAX_LG_NOM_LONGS) {
      throw new SketchesArgumentException(""Requested Sketch (LgK = "" + lgK + "" &gt; 2^26), ""
          + ""either increase the threshold, the rse or both."");
    }
    return lgK;
  }"
"@SuppressWarnings(""unchecked"")
    public final static <T> Tuple4<Stream<T>, Stream<T>, Stream<T>, Stream<T>> quadruplicate(final Stream<T> stream) {
        final Stream<Stream<T>> its = Streams.toBufferingCopier(stream.iterator(), 4)
                                                 .stream()
                                                 .map(it -> Streams.stream(it));
        final Iterator<Stream<T>> it = its.iterator();
        return new Tuple4(
                          it.next(), it.next(), it.next(), it.next());
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.925925925925926, 'avgLineLength': 58.44444444444444, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.1111111111111111, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.35767790262172283}","@SuppressWarnings(""unchecked"")
    public final static <T> Tuple4<Stream<T>, Stream<T>, Stream<T>, Stream<T>> quadruplicate(final Stream<T> stream) {
        final Stream<Stream<T>> its = Streams.toBufferingCopier(stream.iterator(), 4)
                                                 .stream()
                                                 .map(it -> Streams.stream(it));
        final Iterator<Stream<T>> it = its.iterator();
        return new Tuple4(
                          it.next(), it.next(), it.next(), it.next());
    }"
"@XmlElementDecl(namespace = """", name = ""appContext"")
    public JAXBElement<String> createAppContext(String value) {
        return new JAXBElement<String>(_AppContext_QNAME, String.class, null, value);
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 7.894736842105263, 'avgLineLength': 51.25, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.25, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.15865384615384615}","@XmlElementDecl(namespace = """", name = ""appContext"")
    public JAXBElement<String> createAppContext(String value) {
        return new JAXBElement<String>(_AppContext_QNAME, String.class, null, value);
    }"
"public Matrix4d setTranslation(Vector3dc xyz) {
        return setTranslation(xyz.x(), xyz.y(), xyz.z());
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.538461538461538, 'avgLineLength': 36.333333333333336, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.3333333333333333, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.1891891891891892}","public Matrix4d setTranslation(Vector3dc xyz) {
        return setTranslation(xyz.x(), xyz.y(), xyz.z());
    }"
"def delete_query(self, project, query):
        """"""DeleteQuery.
        [Preview API] Delete a query or a folder. This deletes any permission change on the deleted query or folder and any of its descendants if it is a folder. It is important to note that the deleted permission changes cannot be recovered upon undeleting the query or folder.
        :param str project: Project ID or project name
        :param str query: ID or path of the query or folder to delete.
        """"""
        route_values = {}
        if project is not None:
            route_values['project'] = self._serialize.url('project', project, 'str')
        if query is not None:
            route_values['query'] = self._serialize.url('query', query, 'str')
        self._send(http_method='DELETE',
                   location_id='a67d190c-c41f-424b-814d-0e906f659301',
                   version='5.1-preview.2',
                   route_values=route_values)",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.042016806722689, 'avgLineLength': 61.333333333333336, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.06666666666666667, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.27194860813704497}","def delete_query(self, project, query):
        
        route_values = {}
        if project is not None:
            route_values['project'] = self._serialize.url('project', project, 'str')
        if query is not None:
            route_values['query'] = self._serialize.url('query', query, 'str')
        self._send(http_method='DELETE',
                   location_id='a67d190c-c41f-424b-814d-0e906f659301',
                   version='5.1-preview.2',
                   route_values=route_values)"
"private void addTranslationJacobian( Point3D_F64 cameraPt )
	{
		double divZ = 1.0/cameraPt.z;
		double divZ2 = 1.0/(cameraPt.z*cameraPt.z);

		// partial T.x
		output[indexX++] = divZ;
		output[indexY++] = 0;
		// partial T.y
		output[indexX++] = 0;
		output[indexY++] = divZ;
		// partial T.z
		output[indexX++] = -cameraPt.x*divZ2;
		output[indexY++] = -cameraPt.y*divZ2;
	}",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.82, 'avgLineLength': 24.2, 'emptyLinesDensity': 0.06666666666666667, 'functionDefinitionDensity': 0.06666666666666667, 'maintainabilityIndex': 30.97142857142856, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.17771883289124668}","private void addTranslationJacobian( Point3D_F64 cameraPt )
	{
		double divZ = 1.0/cameraPt.z;
		double divZ2 = 1.0/(cameraPt.z*cameraPt.z);

		
		output[indexX++] = divZ;
		output[indexY++] = 0;
		
		output[indexX++] = 0;
		output[indexY++] = divZ;
		
		output[indexX++] = -cameraPt.x*divZ2;
		output[indexY++] = -cameraPt.y*divZ2;
	}"
"private int ringSystemClassifier(IRing ring, String smile) throws CDKException {
        /* System.out.println(""IN AtomTypeTools Smile:""+smile); */
        logger.debug(""Comparing ring systems: SMILES="", smile);
        
        if (PYRROLE_SMI == null) {
            final SmilesParser smipar = new SmilesParser(ring.getBuilder());
            initCache(smipar);
        }

        if (smile.equals(PYRROLE_SMI))
            return PYROLE_RING;
        else if (smile.equals(FURAN_SMI))
            return FURAN_RING;
        else if (smile.equals(THIOPHENE_SMI))
            return THIOPHENE_RING;
        else if (smile.equals(PYRIDINE_SMI))
            return PYRIDINE_RING;
        else if (smile.equals(PYRIMIDINE_SMI))
            return PYRIMIDINE_RING;
        else if (smile.equals(BENZENE_SMI))
            return BENZENE_RING;

        int ncount = 0;
        for (int i = 0; i < ring.getAtomCount(); i++) {
            if (ring.getAtom(i).getSymbol().equals(""N"")) {
                ncount = ncount + 1;
            }
        }

        if (ring.getAtomCount() == 6 & ncount == 1) {
            return 10;
        } else if (ring.getAtomCount() == 5 & ncount == 1) {
            return 4;
        }

        if (ncount == 0) {
            return 3;
        } else {
            return 0;
        }
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.663934426229508, 'avgLineLength': 31.097560975609756, 'emptyLinesDensity': 0.12195121951219512, 'functionDefinitionDensity': 0.024390243902439025, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 6, 'whiteSpaceRatio': 0.36197718631178705}","private int ringSystemClassifier(IRing ring, String smile) throws CDKException {
        
        logger.debug(""Comparing ring systems: SMILES="", smile);
        
        if (PYRROLE_SMI == null) {
            final SmilesParser smipar = new SmilesParser(ring.getBuilder());
            initCache(smipar);
        }

        if (smile.equals(PYRROLE_SMI))
            return PYROLE_RING;
        else if (smile.equals(FURAN_SMI))
            return FURAN_RING;
        else if (smile.equals(THIOPHENE_SMI))
            return THIOPHENE_RING;
        else if (smile.equals(PYRIDINE_SMI))
            return PYRIDINE_RING;
        else if (smile.equals(PYRIMIDINE_SMI))
            return PYRIMIDINE_RING;
        else if (smile.equals(BENZENE_SMI))
            return BENZENE_RING;

        int ncount = 0;
        for (int i = 0; i < ring.getAtomCount(); i++) {
            if (ring.getAtom(i).getSymbol().equals(""N"")) {
                ncount = ncount + 1;
            }
        }

        if (ring.getAtomCount() == 6 & ncount == 1) {
            return 10;
        } else if (ring.getAtomCount() == 5 & ncount == 1) {
            return 4;
        }

        if (ncount == 0) {
            return 3;
        } else {
            return 0;
        }
    }"
"def _ephem_convert_to_seconds_and_microseconds(date):
    # utility from unreleased PyEphem 3.6.7.1
    """"""Converts a PyEphem date into seconds""""""
    microseconds = int(round(24 * 60 * 60 * 1000000 * date))
    seconds, microseconds = divmod(microseconds, 1000000)
    seconds -= 2209032000  # difference between epoch 1900 and epoch 1970
    return seconds, microseconds",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 6.5, 'avgLineLength': 52.285714285714285, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.14285714285714285, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.1827956989247312}","def _ephem_convert_to_seconds_and_microseconds(date):
    
    
    microseconds = int(round(24 * 60 * 60 * 1000000 * date))
    seconds, microseconds = divmod(microseconds, 1000000)
    seconds -= 2209032000  
    return seconds, microseconds"
"public void elementAdded(QueryControllerEntity element) {
		if (element instanceof QueryControllerGroup) {
			QueryControllerGroup group = (QueryControllerGroup) element;
			QueryGroupTreeElement ele = new QueryGroupTreeElement(group.getID());
			insertNodeInto(ele, (DefaultMutableTreeNode) root, root.getChildCount());
			nodeStructureChanged(root);
		} else if (element instanceof QueryControllerQuery) {
			QueryControllerQuery query = (QueryControllerQuery) element;
			QueryTreeElement ele = new QueryTreeElement(query.getID(), query.getQuery());
			insertNodeInto(ele, (DefaultMutableTreeNode) root, root.getChildCount());
			nodeStructureChanged(root);
		}
	}",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 10.057692307692308, 'avgLineLength': 50.38461538461539, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.15384615384615385, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 3, 'whiteSpaceRatio': 0.1199400299850075}","public void elementAdded(QueryControllerEntity element) {
		if (element instanceof QueryControllerGroup) {
			QueryControllerGroup group = (QueryControllerGroup) element;
			QueryGroupTreeElement ele = new QueryGroupTreeElement(group.getID());
			insertNodeInto(ele, (DefaultMutableTreeNode) root, root.getChildCount());
			nodeStructureChanged(root);
		} else if (element instanceof QueryControllerQuery) {
			QueryControllerQuery query = (QueryControllerQuery) element;
			QueryTreeElement ele = new QueryTreeElement(query.getID(), query.getQuery());
			insertNodeInto(ele, (DefaultMutableTreeNode) root, root.getChildCount());
			nodeStructureChanged(root);
		}
	}"
"void nPermute(string str, long long n) {
  sort((str).begin(), (str).end());
  long long i = 1;
  do {

 if (i == n) break;

 i++;
  } while (next_permutation(str.begin(), str.end()));
  cout << str << endl;
}",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 3.7419354838709675, 'avgLineLength': 18.09090909090909, 'emptyLinesDensity': 0.18181818181818182, 'functionDefinitionDensity': 19.09090909090909, 'maintainabilityIndex': 1.9444444444444358, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.215311004784689}","void nPermute(string str, long long n) {
  sort((str).begin(), (str).end());
  long long i = 1;
  do {

 if (i == n) break;

 i++;
  } while (next_permutation(str.begin(), str.end()));
  cout << str << endl;
}"
"def get_partition(url, headers, source_id, container, partition):
    """"""Serializable function for fetching a data source partition

    Parameters
    ----------
    url: str
        Server address
    headers: dict
        HTTP header parameters
    source_id: str
        ID of the source in the server's cache (unique per user)
    container: str
        Type of data, like ""dataframe"" one of ``intake.container.container_map``
    partition: serializable
        Part of data to fetch, e.g., an integer for a dataframe.
    """"""
    accepted_formats = list(serializer.format_registry.keys())
    accepted_compression = list(serializer.compression_registry.keys())
    payload = dict(action='read',
                   source_id=source_id,
                   accepted_formats=accepted_formats,
                   accepted_compression=accepted_compression)

    if partition is not None:
        payload['partition'] = partition

    try:
        resp = requests.post(urljoin(url, '/v1/source'),
                             data=msgpack.packb(payload, use_bin_type=True),
                             **headers)
        if resp.status_code != 200:
            raise Exception('Error reading data')

        msg = msgpack.unpackb(resp.content, **unpack_kwargs)
        format = msg['format']
        compression = msg['compression']
        compressor = serializer.compression_registry[compression]
        encoder = serializer.format_registry[format]
        chunk = encoder.decode(compressor.decompress(msg['data']),
                               container)
        return chunk
    finally:
        if resp is not None:
            resp.close()",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 6.52258064516129, 'avgLineLength': 36.5, 'emptyLinesDensity': 0.09090909090909091, 'functionDefinitionDensity': 0.022727272727272728, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2959369314736204}","def get_partition(url, headers, source_id, container, partition):
    
    accepted_formats = list(serializer.format_registry.keys())
    accepted_compression = list(serializer.compression_registry.keys())
    payload = dict(action='read',
                   source_id=source_id,
                   accepted_formats=accepted_formats,
                   accepted_compression=accepted_compression)

    if partition is not None:
        payload['partition'] = partition

    try:
        resp = requests.post(urljoin(url, '/v1/source'),
                             data=msgpack.packb(payload, use_bin_type=True),
                             **headers)
        if resp.status_code != 200:
            raise Exception('Error reading data')

        msg = msgpack.unpackb(resp.content, **unpack_kwargs)
        format = msg['format']
        compression = msg['compression']
        compressor = serializer.compression_registry[compression]
        encoder = serializer.format_registry[format]
        chunk = encoder.decode(compressor.decompress(msg['data']),
                               container)
        return chunk
    finally:
        if resp is not None:
            resp.close()"
"protected <R extends Closeable> R registerReporter(final R reporter) {
		if (this.reporters == null) {
			this.reporters = new HashSet<Closeable>();
		}
		this.reporters.add(reporter);
		return reporter;
	}",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 6.083333333333333, 'avgLineLength': 28.571428571428573, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.14285714285714285, 'maintainabilityIndex': 17.74142857142856, 'maxDecisionTokens': 3, 'whiteSpaceRatio': 0.1650485436893204}","protected <R extends Closeable> R registerReporter(final R reporter) {
		if (this.reporters == null) {
			this.reporters = new HashSet<Closeable>();
		}
		this.reporters.add(reporter);
		return reporter;
	}"
"inline int readAns(int req) {
  cout << req << endl;
  int q;
  cin >> q;
  if (q == 0) {

 exit(0);
  }
  return q;
}",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 3.0, 'avgLineLength': 10.9, 'emptyLinesDensity': 0.1, 'functionDefinitionDensity': 11.9, 'maintainabilityIndex': 75.45222222222222, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3220338983050847}","inline int readAns(int req) {
  cout << req << endl;
  int q;
  cin >> q;
  if (q == 0) {

 exit(0);
  }
  return q;
}"
"private void handleTmpView(View v) {
        Address new_coord=v.getCoord();
        if(new_coord != null && !new_coord.equals(coord) && local_addr != null && local_addr.equals(new_coord))
            handleViewChange(v);
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 6.590909090909091, 'avgLineLength': 44.6, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.2, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 5, 'whiteSpaceRatio': 0.22466960352422907}","private void handleTmpView(View v) {
        Address new_coord=v.getCoord();
        if(new_coord != null && !new_coord.equals(coord) && local_addr != null && local_addr.equals(new_coord))
            handleViewChange(v);
    }"
"def save(**kwargs):
    '''
    Save all scheduled jobs on the minion

    CLI Example:

    .. code-block:: bash

        salt '*' schedule.save
    '''

    ret = {'comment': [],
           'result': True}

    if 'test' in kwargs and kwargs['test']:
        ret['comment'] = 'Schedule would be saved.'
    else:
        try:
            eventer = salt.utils.event.get_event('minion', opts=__opts__)
            res = __salt__['event.fire']({'func': 'save_schedule'}, 'manage_schedule')
            if res:
                event_ret = eventer.get_event(tag='/salt/minion/minion_schedule_saved', wait=30)
                if event_ret and event_ret['complete']:
                    ret['result'] = True
                    ret['comment'] = 'Schedule (non-pillar items) saved.'
                else:
                    ret['result'] = False
                    ret['comment'] = 'Failed to save schedule.'
        except KeyError:
            # Effectively a no-op, since we can't really return without an event system
            ret['comment'] = 'Event module not available. Schedule save failed.'
    return ret",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.208695652173913, 'avgLineLength': 33.8125, 'emptyLinesDensity': 0.15625, 'functionDefinitionDensity': 0.03125, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3360287511230907}","def save(**kwargs):
    

    ret = {'comment': [],
           'result': True}

    if 'test' in kwargs and kwargs['test']:
        ret['comment'] = 'Schedule would be saved.'
    else:
        try:
            eventer = salt.utils.event.get_event('minion', opts=__opts__)
            res = __salt__['event.fire']({'func': 'save_schedule'}, 'manage_schedule')
            if res:
                event_ret = eventer.get_event(tag='/salt/minion/minion_schedule_saved', wait=30)
                if event_ret and event_ret['complete']:
                    ret['result'] = True
                    ret['comment'] = 'Schedule (non-pillar items) saved.'
                else:
                    ret['result'] = False
                    ret['comment'] = 'Failed to save schedule.'
        except KeyError:
            
            ret['comment'] = 'Event module not available. Schedule save failed.'
    return ret"
"def add_vertex(self, vertex):
        """"""Adds a new vertex to the graph if not present.

        :param vertex: Vertex
        :return: ``True`` if ``vertex`` added and not yet present. ``False`` otherwise.
        """"""
        if vertex not in self._vertices:
            self._vertices.add(vertex)
            return True

        return False",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.714285714285714, 'avgLineLength': 31.272727272727273, 'emptyLinesDensity': 0.18181818181818182, 'functionDefinitionDensity': 0.09090909090909091, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3418079096045198}","def add_vertex(self, vertex):
        
        if vertex not in self._vertices:
            self._vertices.add(vertex)
            return True

        return False"
"public static void constraintMatrix6x3( DMatrixRMaj L_6x10 , DMatrixRMaj L_6x3 ) {

		int index = 0;
		for( int i = 0; i < 6; i++ ) {
			L_6x3.data[index++] = L_6x10.get(i,0);
			L_6x3.data[index++] = L_6x10.get(i,1);
			L_6x3.data[index++] = L_6x10.get(i,4);
		}
	}",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.17948717948718, 'avgLineLength': 28.666666666666668, 'emptyLinesDensity': 0.1111111111111111, 'functionDefinitionDensity': 0.1111111111111111, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 6, 'whiteSpaceRatio': 0.19924812030075187}","public static void constraintMatrix6x3( DMatrixRMaj L_6x10 , DMatrixRMaj L_6x3 ) {

		int index = 0;
		for( int i = 0; i < 6; i++ ) {
			L_6x3.data[index++] = L_6x10.get(i,0);
			L_6x3.data[index++] = L_6x10.get(i,1);
			L_6x3.data[index++] = L_6x10.get(i,4);
		}
	}"
"def execute(self, eopatch):
        """"""
        :param eopatch: Input EOPatch.
        :type eopatch: EOPatch
        :return: Transformed eo patch
        :rtype: EOPatch
        """"""
        feature_type, feature_name = next(self.feature(eopatch))

        good_idxs = self._get_filtered_indices(eopatch[feature_type][feature_name] if feature_name is not ... else
                                               eopatch[feature_type])

        for feature_type, feature_name in self.filter_features(eopatch):
            if feature_type.is_time_dependent():
                if feature_type.has_dict():
                    if feature_type.contains_ndarrays():
                        eopatch[feature_type][feature_name] = np.asarray([eopatch[feature_type][feature_name][idx] for
                                                                          idx in good_idxs])
                    # else:
                    #     NotImplemented
                else:
                    eopatch[feature_type] = [eopatch[feature_type][idx] for idx in good_idxs]

        self._update_other_data(eopatch)

        return eopatch",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 7.365853658536586, 'avgLineLength': 42.15384615384615, 'emptyLinesDensity': 0.15384615384615385, 'functionDefinitionDensity': 0.038461538461538464, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.38269402319357715}","def execute(self, eopatch):
        
        feature_type, feature_name = next(self.feature(eopatch))

        good_idxs = self._get_filtered_indices(eopatch[feature_type][feature_name] if feature_name is not ... else
                                               eopatch[feature_type])

        for feature_type, feature_name in self.filter_features(eopatch):
            if feature_type.is_time_dependent():
                if feature_type.has_dict():
                    if feature_type.contains_ndarrays():
                        eopatch[feature_type][feature_name] = np.asarray([eopatch[feature_type][feature_name][idx] for
                                                                          idx in good_idxs])
                    
                    
                else:
                    eopatch[feature_type] = [eopatch[feature_type][idx] for idx in good_idxs]

        self._update_other_data(eopatch)

        return eopatch"
"def RX(angle, qubit):
    """"""Produces the RX gate::

        RX(phi) = [[cos(phi / 2), -1j * sin(phi / 2)],
                   [-1j * sin(phi / 2), cos(phi / 2)]]

    This gate is a single qubit X-rotation.

    :param angle: The angle to rotate around the x-axis on the bloch sphere.
    :param qubit: The qubit apply the gate to.
    :returns: A Gate object.
    """"""
    return Gate(name=""RX"", params=[angle], qubits=[unpack_qubit(qubit)])",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 3.8208955223880596, 'avgLineLength': 33.07692307692308, 'emptyLinesDensity': 0.23076923076923078, 'functionDefinitionDensity': 0.07692307692307693, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2692307692307692}","def RX(angle, qubit):
    
    return Gate(name=""RX"", params=[angle], qubits=[unpack_qubit(qubit)])"
"def _represent_argument(directive_location, context, argument, inferred_type):
    """"""Return a two-element tuple that represents the argument to the directive being processed.

    Args:
        directive_location: Location where the directive is used.
        context: dict, various per-compilation data (e.g. declared tags, whether the current block
                 is optional, etc.). May be mutated in-place in this function!
        argument: string, the name of the argument to the directive
        inferred_type: GraphQL type object specifying the inferred type of the argument

    Returns:
        (argument_expression, non_existence_expression)
            - argument_expression: an Expression object that captures the semantics of the argument
            - non_existence_expression: None or Expression object;
              If the current block is not optional, this is set to None. Otherwise, it is an
              expression that will evaluate to True if the argument is skipped as optional and
              therefore not present, and False otherwise.
    """"""
    # Regardless of what kind of variable we are dealing with,
    # we want to ensure its name is valid.
    argument_name = argument[1:]
    validate_safe_string(argument_name)

    if is_variable_argument(argument):
        existing_type = context['inputs'].get(argument_name, inferred_type)
        if not inferred_type.is_same_type(existing_type):
            raise GraphQLCompilationError(u'Incompatible types inferred for argument {}. '
                                          u'The argument cannot simultaneously be '
                                          u'{} and {}.'.format(argument, existing_type,
                                                               inferred_type))
        context['inputs'][argument_name] = inferred_type

        return (expressions.Variable(argument, inferred_type), None)
    elif is_tag_argument(argument):
        argument_context = context['tags'].get(argument_name, None)
        if argument_context is None:
            raise GraphQLCompilationError(u'Undeclared argument used: {}'.format(argument))

        location = argument_context['location']
        optional = argument_context['optional']
        tag_inferred_type = argument_context['type']

        if location is None:
            raise AssertionError(u'Argument declared without location: {}'.format(argument_name))

        if location.field is None:
            raise AssertionError(u'Argument location is not a property field: {}'.format(location))

        if not inferred_type.is_same_type(tag_inferred_type):
            raise GraphQLCompilationError(u'The inferred type of the matching @tag directive does '
                                          u'not match the inferred required type for this filter: '
                                          u'{} vs {}'.format(tag_inferred_type, inferred_type))

        # Check whether the argument is a field on the vertex on which the directive is applied.
        field_is_local = directive_location.at_vertex() == location.at_vertex()

        non_existence_expression = None
        if optional:
            if field_is_local:
                non_existence_expression = expressions.FalseLiteral
            else:
                non_existence_expression = expressions.BinaryComposition(
                    u'=',
                    expressions.ContextFieldExistence(location.at_vertex()),
                    expressions.FalseLiteral)

        if field_is_local:
            representation = expressions.LocalField(argument_name)
        else:
            representation = expressions.ContextField(location, tag_inferred_type)

        return (representation, non_existence_expression)
    else:
        # If we want to support literal arguments, add them here.
        raise GraphQLCompilationError(u'Non-argument type found: {}'.format(argument))",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 6.975274725274725, 'avgLineLength': 51.0, 'emptyLinesDensity': 0.16, 'functionDefinitionDensity': 0.013333333333333334, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.28391895357784047}","def _represent_argument(directive_location, context, argument, inferred_type):
    
    
    
    argument_name = argument[1:]
    validate_safe_string(argument_name)

    if is_variable_argument(argument):
        existing_type = context['inputs'].get(argument_name, inferred_type)
        if not inferred_type.is_same_type(existing_type):
            raise GraphQLCompilationError(u'Incompatible types inferred for argument {}. '
                                          u'The argument cannot simultaneously be '
                                          u'{} and {}.'.format(argument, existing_type,
                                                               inferred_type))
        context['inputs'][argument_name] = inferred_type

        return (expressions.Variable(argument, inferred_type), None)
    elif is_tag_argument(argument):
        argument_context = context['tags'].get(argument_name, None)
        if argument_context is None:
            raise GraphQLCompilationError(u'Undeclared argument used: {}'.format(argument))

        location = argument_context['location']
        optional = argument_context['optional']
        tag_inferred_type = argument_context['type']

        if location is None:
            raise AssertionError(u'Argument declared without location: {}'.format(argument_name))

        if location.field is None:
            raise AssertionError(u'Argument location is not a property field: {}'.format(location))

        if not inferred_type.is_same_type(tag_inferred_type):
            raise GraphQLCompilationError(u'The inferred type of the matching @tag directive does '
                                          u'not match the inferred required type for this filter: '
                                          u'{} vs {}'.format(tag_inferred_type, inferred_type))

        
        field_is_local = directive_location.at_vertex() == location.at_vertex()

        non_existence_expression = None
        if optional:
            if field_is_local:
                non_existence_expression = expressions.FalseLiteral
            else:
                non_existence_expression = expressions.BinaryComposition(
                    u'=',
                    expressions.ContextFieldExistence(location.at_vertex()),
                    expressions.FalseLiteral)

        if field_is_local:
            representation = expressions.LocalField(argument_name)
        else:
            representation = expressions.ContextField(location, tag_inferred_type)

        return (representation, non_existence_expression)
    else:
        
        raise GraphQLCompilationError(u'Non-argument type found: {}'.format(argument))"
"public Matrix3f scale(Vector3fc xyz, Matrix3f dest) {
        return scale(xyz.x(), xyz.y(), xyz.z(), dest);
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.375, 'avgLineLength': 37.333333333333336, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.3333333333333333, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.21052631578947367}","public Matrix3f scale(Vector3fc xyz, Matrix3f dest) {
        return scale(xyz.x(), xyz.y(), xyz.z(), dest);
    }"
"@Override
	public CPOptionCategory create(long CPOptionCategoryId) {
		CPOptionCategory cpOptionCategory = new CPOptionCategoryImpl();

		cpOptionCategory.setNew(true);
		cpOptionCategory.setPrimaryKey(CPOptionCategoryId);

		String uuid = PortalUUIDUtil.generate();

		cpOptionCategory.setUuid(uuid);

		cpOptionCategory.setCompanyId(companyProvider.getCompanyId());

		return cpOptionCategory;
	}",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 11.10344827586207, 'avgLineLength': 25.6, 'emptyLinesDensity': 0.3333333333333333, 'functionDefinitionDensity': 0.06666666666666667, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.10552763819095477}","@Override
	public CPOptionCategory create(long CPOptionCategoryId) {
		CPOptionCategory cpOptionCategory = new CPOptionCategoryImpl();

		cpOptionCategory.setNew(true);
		cpOptionCategory.setPrimaryKey(CPOptionCategoryId);

		String uuid = PortalUUIDUtil.generate();

		cpOptionCategory.setUuid(uuid);

		cpOptionCategory.setCompanyId(companyProvider.getCompanyId());

		return cpOptionCategory;
	}"
"@Override
	public void cacheResult(CPOptionCategory cpOptionCategory) {
		entityCache.putResult(CPOptionCategoryModelImpl.ENTITY_CACHE_ENABLED,
			CPOptionCategoryImpl.class, cpOptionCategory.getPrimaryKey(),
			cpOptionCategory);

		finderCache.putResult(FINDER_PATH_FETCH_BY_UUID_G,
			new Object[] {
				cpOptionCategory.getUuid(), cpOptionCategory.getGroupId()
			}, cpOptionCategory);

		finderCache.putResult(FINDER_PATH_FETCH_BY_G_K,
			new Object[] {
				cpOptionCategory.getGroupId(), cpOptionCategory.getKey()
			}, cpOptionCategory);

		cpOptionCategory.resetOriginalValues();
	}",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 12.675675675675675, 'avgLineLength': 31.833333333333332, 'emptyLinesDensity': 0.16666666666666666, 'functionDefinitionDensity': 0.05555555555555555, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.11186440677966102}","@Override
	public void cacheResult(CPOptionCategory cpOptionCategory) {
		entityCache.putResult(CPOptionCategoryModelImpl.ENTITY_CACHE_ENABLED,
			CPOptionCategoryImpl.class, cpOptionCategory.getPrimaryKey(),
			cpOptionCategory);

		finderCache.putResult(FINDER_PATH_FETCH_BY_UUID_G,
			new Object[] {
				cpOptionCategory.getUuid(), cpOptionCategory.getGroupId()
			}, cpOptionCategory);

		finderCache.putResult(FINDER_PATH_FETCH_BY_G_K,
			new Object[] {
				cpOptionCategory.getGroupId(), cpOptionCategory.getKey()
			}, cpOptionCategory);

		cpOptionCategory.resetOriginalValues();
	}"
"def success(request, message, extra_tags='', fail_silently=False):
    """"""Adds a message with the ``SUCCESS`` level.""""""
    add_message(request, constants.SUCCESS, message, extra_tags=extra_tags,
                fail_silently=fail_silently)",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 7.391304347826087, 'avgLineLength': 59.25, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.25, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.16666666666666666}","def success(request, message, extra_tags='', fail_silently=False):
    
    add_message(request, constants.SUCCESS, message, extra_tags=extra_tags,
                fail_silently=fail_silently)"
"bool discover(int n, const vector<string>& ma, vector<vector<int> >& has_p) {
  bool found = false;
  for (int i = 0; i < (n); ++i) {

 for (int j = 0; j < (n); ++j) {


int points = ma[i][j] -  0 ;


int has_point = 0;


int no_point = 0;


for (int u = 0; u < (2); ++u) {


  for (int v = 0; v < (2); ++v) {



 int i1 = i + u;



 int j1 = j + v;



 has_point += has_p[i1][j1] == 1;



 no_point += has_p[i1][j1] == -1;


  }


}


points -= has_point;


int left_points = 4 - has_point - no_point;


if ((points == 0 || points == left_points) && left_points > 0) {


  found = true;


  int val = points == 0 ? -1 : 1;


  for (int u = 0; u < (2); ++u) {



 for (int v = 0; v < (2); ++v) {




int i1 = i + u;




int j1 = j + v;




if (has_p[i1][j1] == 0) {




  has_p[i1][j1] = val;




}



 }


  }


}

 }
  }
  return found;
}",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 2.9921875, 'avgLineLength': 7.086538461538462, 'emptyLinesDensity': 0.6730769230769231, 'functionDefinitionDensity': 8.086538461538462, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.33214285714285713}","bool discover(int n, const vector<string>& ma, vector<vector<int> >& has_p) {
  bool found = false;
  for (int i = 0; i < (n); ++i) {

 for (int j = 0; j < (n); ++j) {


int points = ma[i][j] -  0 ;


int has_point = 0;


int no_point = 0;


for (int u = 0; u < (2); ++u) {


  for (int v = 0; v < (2); ++v) {



 int i1 = i + u;



 int j1 = j + v;



 has_point += has_p[i1][j1] == 1;



 no_point += has_p[i1][j1] == -1;


  }


}


points -= has_point;


int left_points = 4 - has_point - no_point;


if ((points == 0 || points == left_points) && left_points > 0) {


  found = true;


  int val = points == 0 ? -1 : 1;


  for (int u = 0; u < (2); ++u) {



 for (int v = 0; v < (2); ++v) {




int i1 = i + u;




int j1 = j + v;




if (has_p[i1][j1] == 0) {




  has_p[i1][j1] = val;




}



 }


  }


}

 }
  }
  return found;
}"
"def satisfies_constraint(self, site):
        """"""
        Checks if a periodic site satisfies the constraint.
        """"""
        if not site.is_ordered:
            return False

        if self.species_constraints \
                and str(site.specie) in self.species_constraints:
            satisfies_constraints = True
        else:
            satisfies_constraints = False

        if self.site_constraint_name \
                and self.site_constraint_name in site.properties:
            prop = site.properties[self.site_constraint_name]
            if prop in self.site_constraints:
                satisfies_constraints = True
            else:
                satisfies_constraints = False

        return satisfies_constraints",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 7.559322033898305, 'avgLineLength': 32.72727272727273, 'emptyLinesDensity': 0.13636363636363635, 'functionDefinitionDensity': 0.045454545454545456, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3468286099865047}","def satisfies_constraint(self, site):
        
        if not site.is_ordered:
            return False

        if self.species_constraints \
                and str(site.specie) in self.species_constraints:
            satisfies_constraints = True
        else:
            satisfies_constraints = False

        if self.site_constraint_name \
                and self.site_constraint_name in site.properties:
            prop = site.properties[self.site_constraint_name]
            if prop in self.site_constraints:
                satisfies_constraints = True
            else:
                satisfies_constraints = False

        return satisfies_constraints"
"def get_structure(atoms, cls=None):
        """"""
        Returns pymatgen structure from ASE Atoms.

        Args:
            atoms: ASE Atoms object
            cls: The Structure class to instantiate (defaults to pymatgen structure)

        Returns:
            Equivalent pymatgen.core.structure.Structure
        """"""
        symbols = atoms.get_chemical_symbols()
        positions = atoms.get_positions()
        lattice = atoms.get_cell()

        cls = Structure if cls is None else cls
        return cls(lattice, symbols, positions,
                   coords_are_cartesian=True)",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 6.410714285714286, 'avgLineLength': 31.72222222222222, 'emptyLinesDensity': 0.16666666666666666, 'functionDefinitionDensity': 0.05555555555555555, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.32142857142857145}","def get_structure(atoms, cls=None):
        
        symbols = atoms.get_chemical_symbols()
        positions = atoms.get_positions()
        lattice = atoms.get_cell()

        cls = Structure if cls is None else cls
        return cls(lattice, symbols, positions,
                   coords_are_cartesian=True)"
"def get(self, name):
        """"""Retrieve a plugin by name.""""""
        try:
            return self.plugins[name]
        except KeyError:
            raise RuntimeError(""plugin {} does not exist"".format(name))",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.916666666666667, 'avgLineLength': 34.0, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.16666666666666666, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3157894736842105}","def get(self, name):
        
        try:
            return self.plugins[name]
        except KeyError:
            raise RuntimeError(""plugin {} does not exist"".format(name))"
"def _remove_ordered_from_queue(self, last_caught_up_3PC=None):
        """"""
        Remove any Ordered that the replica might be sending to node which is
        less than or equal to `last_caught_up_3PC` if `last_caught_up_3PC` is
        passed else remove all ordered, needed in catchup
        """"""
        to_remove = []
        for i, msg in enumerate(self.outBox):
            if isinstance(msg, Ordered) and \
                    (not last_caught_up_3PC or
                     compare_3PC_keys((msg.viewNo, msg.ppSeqNo), last_caught_up_3PC) >= 0):
                to_remove.append(i)

        self.logger.trace('{} going to remove {} Ordered messages from outbox'.format(self, len(to_remove)))

        # Removing Ordered from queue but returning `Ordered` in order that
        # they should be processed.
        removed = []
        for i in reversed(to_remove):
            removed.insert(0, self.outBox[i])
            del self.outBox[i]
        return removed",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 5.579439252336448, 'avgLineLength': 43.22727272727273, 'emptyLinesDensity': 0.09090909090909091, 'functionDefinitionDensity': 0.045454545454545456, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.30246913580246915}","def _remove_ordered_from_queue(self, last_caught_up_3PC=None):
        
        to_remove = []
        for i, msg in enumerate(self.outBox):
            if isinstance(msg, Ordered) and \
                    (not last_caught_up_3PC or
                     compare_3PC_keys((msg.viewNo, msg.ppSeqNo), last_caught_up_3PC) >= 0):
                to_remove.append(i)

        self.logger.trace('{} going to remove {} Ordered messages from outbox'.format(self, len(to_remove)))

        
        
        removed = []
        for i in reversed(to_remove):
            removed.insert(0, self.outBox[i])
            del self.outBox[i]
        return removed"
"def get_branches(self, project, repository, base=None, filter=None, start=0, limit=99999, details=True,
                     order_by='MODIFICATION'):
        """"""
        Retrieve the branches matching the supplied filterText param.
        The authenticated user must have REPO_READ permission for the specified repository to call this resource.
        :param start:
        :param project:
        :param repository:
        :param base: base branch/tag to compare each branch to (for the metadata providers that uses that information)
        :param filter:
        :param limit: OPTIONAL: The limit of the number of branches to return, this may be restricted by
                    fixed system limits. Default by built-in method: 99999
        :param details: whether to retrieve plugin-provided metadata about each branch
        :param order_by: OPTIONAL: ordering of refs either ALPHABETICAL (by name) or MODIFICATION (last updated)
        :return:
        """"""
        url = 'rest/api/1.0/projects/{project}/repos/{repository}/branches'.format(project=project,
                                                                                   repository=repository)
        params = {}
        if start:
            params['start'] = start
        if limit:
            params['limit'] = limit
        if filter:
            params['filterText'] = filter
        if base:
            params['base'] = base
        if order_by:
            params['orderBy'] = order_by
        params['details'] = details

        return (self.get(url, params=params) or {}).get('values')",python,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 5.491228070175438, 'avgLineLength': 48.4375, 'emptyLinesDensity': 0.03125, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3225806451612903}","def get_branches(self, project, repository, base=None, filter=None, start=0, limit=99999, details=True,
                     order_by='MODIFICATION'):
        
        url = 'rest/api/1.0/projects/{project}/repos/{repository}/branches'.format(project=project,
                                                                                   repository=repository)
        params = {}
        if start:
            params['start'] = start
        if limit:
            params['limit'] = limit
        if filter:
            params['filterText'] = filter
        if base:
            params['base'] = base
        if order_by:
            params['orderBy'] = order_by
        params['details'] = details

        return (self.get(url, params=params) or {}).get('values')"
"inline char rrc() {
  char c;
  while (c = getchar(), c <=
 )

 ;
  return c;
}",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 3.5454545454545454, 'avgLineLength': 9.0, 'emptyLinesDensity': 0.125, 'functionDefinitionDensity': 10.0, 'maintainabilityIndex': 93.91428571428571, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.31645569620253167}","inline char rrc() {
  char c;
  while (c = getchar(), c <=
 )

 ;
  return c;
}"
"bool isReachable(int x, int y) {
  bool ans = false;
  int rootx = getDsuRoot(x), rooty = getDsuRoot(y);
  if (rootx == rooty || adj[rootx].find(y) != adj[rootx].end()) ans = true;
  return ans;
}",cpp,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.066666666666666, 'avgLineLength': 31.833333333333332, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 32.833333333333336, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.19387755102040816}","bool isReachable(int x, int y) {
  bool ans = false;
  int rootx = getDsuRoot(x), rooty = getDsuRoot(y);
  if (rootx == rooty || adj[rootx].find(y) != adj[rootx].end()) ans = true;
  return ans;
}"
"public static TaxRate retrieve(String taxRate) throws StripeException {
    return retrieve(taxRate, (Map<String, Object>) null, (RequestOptions) null);
  }",java,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 7.0, 'avgLineLength': 51.333333333333336, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.1346153846153846}","public static TaxRate retrieve(String taxRate) throws StripeException {
    return retrieve(taxRate, (Map<String, Object>) null, (RequestOptions) null);
  }"
"def setup_network_id_or_exit(
        config: Dict[str, Any],
        given_network_id: int,
        web3: Web3,
) -> Tuple[int, bool]:
    """"""
    Takes the given network id and checks it against the connected network

    If they don't match, exits the program with an error. If they do adds it
    to the configuration and then returns it and whether it is a known network
    """"""
    node_network_id = int(web3.version.network)  # pylint: disable=no-member
    known_given_network_id = given_network_id in ID_TO_NETWORKNAME
    known_node_network_id = node_network_id in ID_TO_NETWORKNAME

    if node_network_id != given_network_id:
        if known_given_network_id and known_node_network_id:
            click.secho(
                f""The chosen ethereum network '{ID_TO_NETWORKNAME[given_network_id]}' ""
                f""differs from the ethereum client '{ID_TO_NETWORKNAME[node_network_id]}'. ""
                ""Please update your settings."",
                fg='red',
            )
        else:
            click.secho(
                f""The chosen ethereum network id '{given_network_id}' differs ""
                f""from the ethereum client '{node_network_id}'. ""
                ""Please update your settings."",
                fg='red',
            )
        sys.exit(1)

    config['chain_id'] = given_network_id
    return given_network_id, known_node_network_id",python,human,train,human,gh,"{'avgFunctionLength': 0.0, 'avgIdentifierLength': 6.537313432835821, 'avgLineLength': 39.588235294117645, 'emptyLinesDensity': 0.08823529411764706, 'functionDefinitionDensity': 0.0, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.290065264684554}","def setup_network_id_or_exit(
        config: Dict[str, Any],
        given_network_id: int,
        web3: Web3,
) -> Tuple[int, bool]:
    
    node_network_id = int(web3.version.network)  
    known_given_network_id = given_network_id in ID_TO_NETWORKNAME
    known_node_network_id = node_network_id in ID_TO_NETWORKNAME

    if node_network_id != given_network_id:
        if known_given_network_id and known_node_network_id:
            click.secho(
                f""The chosen ethereum network '{ID_TO_NETWORKNAME[given_network_id]}' ""
                f""differs from the ethereum client '{ID_TO_NETWORKNAME[node_network_id]}'. ""
                ""Please update your settings."",
                fg='red',
            )
        else:
            click.secho(
                f""The chosen ethereum network id '{given_network_id}' differs ""
                f""from the ethereum client '{node_network_id}'. ""
                ""Please update your settings."",
                fg='red',
            )
        sys.exit(1)

    config['chain_id'] = given_network_id
    return given_network_id, known_node_network_id"
"def _init_itemid2name(self):
        """"""Print gene symbols instead of gene IDs, if provided.""""""
        if not hasattr(self.args, 'id2sym'):
            return None
        fin_id2sym = self.args.id2sym
        if fin_id2sym is not None and os.path.exists(fin_id2sym):
            id2sym = {}
            cmpl = re.compile(r'^\s*(\S+)[\s,;]+(\S+)')
            with open(fin_id2sym) as ifstrm:
                for line in ifstrm:
                    mtch = cmpl.search(line)
                    if mtch:
                        id2sym[mtch.group(1)] = mtch.group(2)
            return id2sym",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.462686567164179, 'avgLineLength': 41.285714285714285, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.07142857142857142, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3756345177664975}","def _init_itemid2name(self):
        
        if not hasattr(self.args, 'id2sym'):
            return None
        fin_id2sym = self.args.id2sym
        if fin_id2sym is not None and os.path.exists(fin_id2sym):
            id2sym = {}
            cmpl = re.compile(r'^\s*(\S+)[\s,;]+(\S+)')
            with open(fin_id2sym) as ifstrm:
                for line in ifstrm:
                    mtch = cmpl.search(line)
                    if mtch:
                        id2sym[mtch.group(1)] = mtch.group(2)
            return id2sym"
"def flatten_json_request_body(prefix, dict_body, spec):
    """"""Convert a JSON request body into query params.""""""
    if len(spec) == 1 and 'type' in spec:
        return {prefix: to_str(dict_body, spec)}

    flat = {}
    for key, value in dict_body.items():
        node_type = spec[key]['type']
        if node_type == 'list':
            for idx, v in enumerate(value, 1):
                pref = key + '.member.' + str(idx)
                flat.update(flatten_json_request_body(
                    pref, v, spec[key]['member']))
        elif node_type == 'map':
            for idx, (k, v) in enumerate(value.items(), 1):
                pref = key + '.entry.' + str(idx)
                flat.update(flatten_json_request_body(
                    pref + '.key', k, spec[key]['key']))
                flat.update(flatten_json_request_body(
                    pref + '.value', v, spec[key]['value']))
        else:
            flat.update(flatten_json_request_body(key, value, spec[key]))

    if prefix:
        prefix = prefix + '.'
    return dict((prefix + k, v) for k, v in flat.items())",python,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 4.940677966101695, 'avgLineLength': 41.19230769230769, 'emptyLinesDensity': 0.07692307692307693, 'functionDefinitionDensity': 0.038461538461538464, 'maintainabilityIndex': 0.0, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.3248175182481752}","def flatten_json_request_body(prefix, dict_body, spec):
    
    if len(spec) == 1 and 'type' in spec:
        return {prefix: to_str(dict_body, spec)}

    flat = {}
    for key, value in dict_body.items():
        node_type = spec[key]['type']
        if node_type == 'list':
            for idx, v in enumerate(value, 1):
                pref = key + '.member.' + str(idx)
                flat.update(flatten_json_request_body(
                    pref, v, spec[key]['member']))
        elif node_type == 'map':
            for idx, (k, v) in enumerate(value.items(), 1):
                pref = key + '.entry.' + str(idx)
                flat.update(flatten_json_request_body(
                    pref + '.key', k, spec[key]['key']))
                flat.update(flatten_json_request_body(
                    pref + '.value', v, spec[key]['value']))
        else:
            flat.update(flatten_json_request_body(key, value, spec[key]))

    if prefix:
        prefix = prefix + '.'
    return dict((prefix + k, v) for k, v in flat.items())"
"@NonNull
    public SourceParams setUsage(@NonNull @Source.Usage String usage) {
        mUsage = usage;
        return this;
    }",java,human,train,human,gh,"{'avgFunctionLength': 1.0, 'avgIdentifierLength': 6.384615384615385, 'avgLineLength': 25.4, 'emptyLinesDensity': 0.0, 'functionDefinitionDensity': 0.2, 'maintainabilityIndex': 34.75999999999999, 'maxDecisionTokens': 0, 'whiteSpaceRatio': 0.2824427480916031}","@NonNull
    public SourceParams setUsage(@NonNull @Source.Usage String usage) {
        mUsage = usage;
        return this;
    }"
